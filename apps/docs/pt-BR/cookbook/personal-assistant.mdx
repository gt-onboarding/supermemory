---
title: "Assistente de IA pessoal"
description: "Crie um assistente de IA que se lembra das prefer√™ncias, h√°bitos e do contexto do usu√°rio ao longo das conversas"
---

Crie um assistente de IA pessoal que aprende e se lembra de tudo sobre o usu√°rio ‚Äî suas prefer√™ncias, h√°bitos, contexto de trabalho e hist√≥rico de conversas. Esta receita mostra como criar uma experi√™ncia de IA verdadeiramente personalizada usando as Memory Tools da Supermemory.

<div id="what-youll-build">
  ## O que voc√™ vai construir
</div>

Um assistente de IA pessoal que:

- **Lembra as prefer√™ncias do usu√°rio** (restri√ß√µes alimentares, agenda de trabalho, estilo de comunica√ß√£o)
- **Aprende com as conversas** e melhora as respostas ao longo do tempo
- **Mant√©m o contexto** ao longo de v√°rias sess√µes de chat
- **Fornece recomenda√ß√µes personalizadas** com base no hist√≥rico do usu√°rio
- **Consegue lidar com v√°rios t√≥picos de conversa** sem perder o contexto

<div id="prerequisites">
  ## Pr√©-requisitos
</div>

- Node.js 18+ ou Python 3.8+
- Chave da API do Supermemory
- Chave da API da OpenAI ou da Anthropic
- No√ß√µes b√°sicas sobre aplicativos de chat

<div id="implementation">
  ## Implementa√ß√£o
</div>

<div id="step-1-project-setup">
  ### Etapa 1: Configura√ß√£o do projeto
</div>

<Tabs>
  <Tab title="Next.js (TypeScript)">
    ```bash
    npx create-next-app@latest personal-ai --typescript --tailwind --eslint
    cd personal-ai
    npm install @supermemory/tools ai openai
    ```

    Crie as vari√°veis de ambiente:
    ```bash .env.local
    SUPERMEMORY_API_KEY=your_supermemory_key
    OPENAI_API_KEY=your_openai_key
    ```
  </Tab>

  <Tab title="Python">
    ```bash
    mkdir personal-ai && cd personal-ai
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    pip install supermemory openai fastapi uvicorn python-multipart
    ```

    Crie as vari√°veis de ambiente:
    ```bash .env
    SUPERMEMORY_API_KEY=your_supermemory_key
    OPENAI_API_KEY=your_openai_key
    ```
  </Tab>
</Tabs>

<div id="step-2-core-assistant-logic">
  ### Etapa 2: L√≥gica Principal do Assistente
</div>

<Tabs>
  <Tab title="Rota de API do Next.js">
    ```typescript app/api/chat/route.ts
    import { streamText } from 'ai'
    import { createOpenAI } from '@ai-sdk/openai'
    import { supermemoryTools } from '@supermemory/tools/ai-sdk'

    const openai = createOpenAI({
      apiKey: process.env.OPENAI_API_KEY!
    })

    export async function POST(request: Request) {
      const { messages, userId = 'default-user' } = await request.json()

      const result = await streamText({
        model: openai('gpt-5'),
        messages,
        tools: supermemoryTools(process.env.SUPERMEMORY_API_KEY!, {
          containerTags: [userId]
        }),
        system: `Voc√™ √© um assistente de IA altamente personalizado. Seu principal objetivo √© aprender sobre o usu√°rio e oferecer ajuda cada vez mais personalizada ao longo do tempo.

    GERENCIAMENTO DE MEMORY:
    1. Quando os usu√°rios compartilharem informa√ß√µes pessoais, prefer√™ncias ou contexto, use imediatamente addMemory para armazenar esses dados
    2. Antes de responder √†s solicita√ß√µes, pesquise suas mem√≥rias em busca de contexto relevante sobre o usu√°rio
    3. Use conversas anteriores para orientar as respostas atuais
    4. Memorize o estilo de comunica√ß√£o do usu√°rio, suas prefer√™ncias e os t√≥picos discutidos com frequ√™ncia

    PERSONALIDADE:
    - Adapte seu estilo de comunica√ß√£o √†s prefer√™ncias do usu√°rio
    - Fa√ßa refer√™ncia a conversas anteriores de forma natural quando for relevante
    - Ofere√ßa ajuda proativamente com base em padr√µes aprendidos
    - Seja genuinamente prestativo, respeitando a privacidade

    EXEMPLOS DO QUE LEMBRAR:
    - Agenda e fun√ß√£o de trabalho
    - Prefer√™ncias/restri√ß√µes alimentares
    - Prefer√™ncias de comunica√ß√£o (formal/informal)
    - T√≥picos de interesse frequentes
    - Metas e projetos em que a pessoa est√° trabalhando
    - Contexto familiar/pessoal compartilhado
    - Ferramentas e fluxos de trabalho preferidos
    - Fuso hor√°rio e disponibilidade

    Sempre pesquise suas mem√≥rias antes de responder para oferecer ajuda personalizada e contextual.`
      })

      return result.toAIStreamResponse()
    }
    ```
  </Tab>

  <Tab title="Python FastAPI">
    ```python main.py
    from fastapi import FastAPI, HTTPException
    from fastapi.responses import StreamingResponse
    import openai
    from supermemory import Supermemory
    import json
    import os
    from typing import List, Dict, Any
    import asyncio

    app = FastAPI()

    openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    supermemory_client = Supermemory(api_key=os.getenv("SUPERMEMORY_API_KEY"))

    SYSTEM_PROMPT = """Voc√™ √© um assistente de IA altamente personalizado. Seu principal objetivo √© aprender sobre o usu√°rio e fornecer ajuda cada vez mais personalizada ao longo do tempo.

    GERENCIAMENTO DE MEM√ìRIAS:
    1. Quando os usu√°rios compartilharem informa√ß√µes pessoais, prefer√™ncias ou contexto, armazene-as imediatamente
    2. Antes de responder √†s solicita√ß√µes, pesquise por contexto relevante sobre o usu√°rio
    3. Use conversas anteriores para embasar as respostas atuais
    4. Lembre-se do estilo de comunica√ß√£o, das prefer√™ncias e dos t√≥picos frequentemente discutidos pelo usu√°rio

    PERSONALIDADE:
    - Adapte seu estilo de comunica√ß√£o √†s prefer√™ncias do usu√°rio
    - Fa√ßa refer√™ncia a conversas anteriores de forma natural quando for relevante
    - Ofere√ßa ajuda proativamente com base em padr√µes aprendidos
    - Seja genuinamente prestativo, respeitando a privacidade

    Sempre pesquise mem√≥rias antes de responder para fornecer ajuda personalizada e contextual."""

    async def search_user_memories(query: str, user_id: str) -> str:
        """Pesquisar mem√≥rias do usu√°rio por contexto relevante"""
        try:
            results = supermemory_client.search.memories(
                q=query,
                container_tag=f"user_{user_id}",
                limit=5
            )

            if results.results:
                context = "\n".join([r.memory for r in results.results])
                return f"Mem√≥rias relevantes sobre o usu√°rio:\n{context}"
            return "Nenhuma mem√≥ria relevante encontrada."
        except Exception as e:
            return f"Erro ao pesquisar mem√≥rias: {e}"

    async def add_user_memory(content: str, user_id: str):
        """Adicionar novas informa√ß√µes √† mem√≥ria do usu√°rio"""
        try:
            supermemory_client.memories.add(
                content=content,
                container_tag=f"user_{user_id}",
                metadata={"type": "personal_info", "timestamp": "auto"}
            )
        except Exception as e:
            print(f"Erro ao adicionar mem√≥ria: {e}")

    @app.post("/chat")
    async def chat_endpoint(data: dict):
        messages = data.get("messages", [])
        user_id = data.get("userId", "default-user")

        if not messages:
            raise HTTPException(status_code=400, detail="Nenhuma mensagem fornecida")

        # Obter a √∫ltima mensagem do usu√°rio para a busca por mem√≥rias
        user_message = messages[-1]["content"] if messages else ""

        # Pesquisar mem√≥rias relevantes
        memory_context = await search_user_memories(user_message, user_id)

        # Adicionar mensagem de sistema com o contexto de mem√≥rias
        enhanced_messages = [
            {"role": "system", "content": f"{SYSTEM_PROMPT}\n\n{memory_context}"}
        ] + messages

        try:
            response = await openai_client.chat.completions.create(
                model="gpt-5",
                messages=enhanced_messages,
                stream=True,
                temperature=0.7
            )

            async def generate():
                full_response = ""
                async for chunk in response:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        yield f"data: {json.dumps({'content': content})}\n\n"

                # Ap√≥s a resposta ser conclu√≠da, analisar conte√∫do que valha ser memorizado
                if "remember" in user_message.lower() or any(word in user_message.lower() for word in ["prefer", "like", "dislike", "work", "schedule", "diet"]):
                    await add_user_memory(user_message, user_id)

            return StreamingResponse(generate(), media_type="text/plain")

        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    if __name__ == "__main__":
        import uvicorn
        uvicorn.run(app, host="0.0.0.0", port=8000)
    ```
  </Tab>
</Tabs>

<div id="step-3-frontend-interface">
  ### Etapa 3: Interface do Frontend
</div>

<Tabs>
  <Tab title="Componente de Chat em Next.js">
    ```tsx app/page.tsx
    'use client'

    import { useChat } from 'ai/react'
    import { useState, useEffect } from 'react'

    export default function PersonalAssistant() {
      const [userId, setUserId] = useState('')
      const [userName, setUserName] = useState('')

      const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
        api: '/api/chat',
        body: {
          userId
        }
      })

      // Gerar ou recuperar o ID do usu√°rio
      useEffect(() => {
        const storedUserId = localStorage.getItem('personal-ai-user-id')
        const storedUserName = localStorage.getItem('personal-ai-user-name')

        if (storedUserId) {
          setUserId(storedUserId)
          setUserName(storedUserName || '')
        } else {
          const newUserId = `user_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
          localStorage.setItem('personal-ai-user-id', newUserId)
          setUserId(newUserId)
        }
      }, [])

      const handleNameSubmit = (e: React.FormEvent) => {
        e.preventDefault()
        if (userName.trim()) {
          localStorage.setItem('personal-ai-user-name', userName)
          // Enviar mensagem de apresenta√ß√£o
          handleSubmit(e, {
            data: {
              content: `Oi! Meu nome √© ${userName}. Estou buscando um assistente de IA pessoal que possa aprender sobre mim e me ajudar com v√°rias tarefas.`
            }
          })
        }
      }

      return (
        <div className="flex flex-col h-screen max-w-4xl mx-auto p-4">
          {/* Cabe√ßalho */}
          <div className="bg-gradient-to-r from-blue-500 to-purple-600 text-white p-6 rounded-lg mb-6">
            <h1 className="text-2xl font-bold">Assistente de IA Pessoal</h1>
            <p className="text-blue-100">
              {userName ? `Ol√°, ${userName}!` : 'Sua IA que aprende e lembra'}
            </p>
          </div>

          {/* Defini√ß√£o de nome */}
          {!userName && (
            <div className="bg-white border border-gray-200 rounded-lg p-6 mb-6">
              <form onSubmit={handleNameSubmit} className="flex gap-2">
                <input
                  type="text"
                  value={userName}
                  onChange={(e) => setUserName(e.target.value)}
                  placeholder="Como devo chamar voc√™?"
                  className="flex-1 p-2 border border-gray-300 rounded focus:outline-none focus:ring-2 focus:ring-blue-500"
                />
                <button
                  type="submit"
                  className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500"
                >
                  Come√ßar
                </button>
              </form>
            </div>
          )}

          {/* Mensagens */}
          <div className="flex-1 overflow-y-auto space-y-4 mb-4">
            {messages.length === 0 && userName && (
              <div className="bg-gray-50 border border-gray-200 rounded-lg p-4">
                <p className="text-gray-600">
                  Oi, {userName}! Sou seu assistente de IA pessoal. Vou aprender sobre suas prefer√™ncias,
                  seu estilo de trabalho e seus interesses conforme conversamos. Fique √† vontade para compartilhar qualquer coisa que voc√™ queira que eu lembre!
                </p>
                <div className="mt-3 text-sm text-gray-500">
                  <p><strong>Tente dizer:</strong></p>
                  <ul className="list-disc list-inside mt-1 space-y-1">
                    <li>"Trabalho como engenheiro(a) de software e prefiro respostas concisas"</li>
                    <li>"Lembre que sou vegetariano(a) e al√©rgico(a) a nozes"</li>
                    <li>"Geralmente trabalho das 9h √†s 17h (EST) e almo√ßo ao meio‚Äëdia"</li>
                  </ul>
                </div>
              </div>
            )}

            {messages.map((message) => (
              <div
                key={message.id}
                className={`p-4 rounded-lg ${
                  message.role === 'user'
                    ? 'bg-blue-500 text-white ml-auto max-w-2xl'
                    : 'bg-white border border-gray-200 max-w-2xl'
                }`}
              >
                <div className="flex items-start space-x-2">
                  {message.role === 'assistant' && (
                    <div className="w-8 h-8 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full flex items-center justify-center text-white text-sm font-bold">
                      IA
                    </div>
                  )}
                  <div className="flex-1">
                    <p className="whitespace-pre-wrap">{message.content}</p>
                  </div>
                </div>
              </div>
            ))}

            {isLoading && (
              <div className="bg-white border border-gray-200 rounded-lg p-4 max-w-2xl">
                <div className="flex items-center space-x-2">
                  <div className="w-8 h-8 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full flex items-center justify-center text-white text-sm font-bold">
                  IA
                  </div>
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"></div>
                    <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                    <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                  </div>
                </div>
              </div>
            )}
          </div>

          {/* Entrada */}
          {userName && (
            <form onSubmit={handleSubmit} className="flex gap-2">
              <input
                value={input}
                onChange={handleInputChange}
                placeholder="Conte algo sobre voc√™ ou pe√ßa ajuda..."
                className="flex-1 p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
                disabled={isLoading}
              />
              <button
                type="submit"
                disabled={isLoading || !input.trim()}
                className="px-6 py-3 bg-blue-500 text-white rounded-lg hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:opacity-50 disabled:cursor-not-allowed"
              >
                Enviar
              </button>
            </form>
          )}
        </div>
      )
    }
    ```
  </Tab>

  <Tab title="Python Streamlit">
    ```python streamlit_app.py
    import streamlit as st
    import requests
    import json
    import uuid

    st.set_page_config(page_title="Assistente de IA Pessoal", page_icon="ü§ñ", layout="wide")

    # Initialize session state
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'user_id' not in st.session_state:
        st.session_state.user_id = f"user_{uuid.uuid4().hex[:8]}"
    if 'user_name' not in st.session_state:
        st.session_state.user_name = None

    # Cabe√ßalho
    st.title("ü§ñ Assistente de IA Pessoal")
    st.markdown("*Sua IA que aprende e lembra*")

    # Barra lateral com informa√ß√µes do usu√°rio
    with st.sidebar:
        st.header("üë§ Perfil do usu√°rio")

        if not st.session_state.user_name:
            name = st.text_input("Como voc√™ quer que eu te chame?")
            if st.button("Come√ßar") and name:
                st.session_state.user_name = name
                st.session_state.messages.append({
                    "role": "user",
                    "content": f"Oi! Meu nome √© {name}. Estou procurando um assistente de IA pessoal."
                })
                st.rerun()
        else:
            st.write(f"**Nome:** {st.session_state.user_name}")
            st.write(f"**ID do usu√°rio:** {st.session_state.user_id[:12]}...")

            if st.button("Reiniciar conversa"):
                st.session_state.messages = []
                st.rerun()

        st.markdown("---")
        st.markdown("""
        ### üí° Experimente dizer:
        - "Sou engenheiro(a) de software e prefiro respostas concisas"
        - "Lembre que sou vegetariano(a)"
        - "Costumo trabalhar das 9h √†s 17h (hor√°rio do leste, EST)"
        """)

    # Interface principal do chat
    if st.session_state.user_name:
        # Exibir mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Entrada do chat
        if prompt := st.chat_input("Conte algo sobre voc√™ ou pe√ßa ajuda..."):
            # Adicionar mensagem do usu√°rio
            st.session_state.messages.append({"role": "user", "content": prompt})

            with st.chat_message("user"):
                st.markdown(prompt)

            # Obter resposta da IA
            with st.chat_message("assistant"):
                with st.spinner("Pensando..."):
                    try:
                        response = requests.post(
                            "http://localhost:8000/chat",
                            json={
                                "messages": st.session_state.messages,
                                "userId": st.session_state.user_id
                            },
                            timeout=30
                        )

                        if response.status_code == 200:
                            # Tratar resposta em streaming
                            full_response = ""
                            for line in response.iter_lines():
                                if line:
                                    try:
                                        data = json.loads(line.decode('utf-8').replace('data: ', ''))
                                        if 'content' in data:
                                            full_response += data['content']
                                    except:
                                        continue

                            st.markdown(full_response)
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": full_response
                            })
                        else:
                            st.error(f"Erro: {response.status_code}")
                    except Exception as e:
                        st.error(f"Erro de conex√£o: {e}")

    else:
        st.info("üëÜ Insira seu nome na barra lateral para come√ßar!")

    # Execute com: streamlit run streamlit_app.py
    ```
  </Tab>
</Tabs>

<div id="testing-your-assistant">
  ## Testando seu Assistente
</div>

<div id="step-4-test-memory-formation">
  ### Etapa 4: Testar a forma√ß√£o de memory
</div>

Experimente estes fluxos de conversa para testar as capacidades de memory:

1. **Prefer√™ncias pessoais**:
   ```
   User: "Oi! Sou a Sarah, gerente de produto em uma startup de tecnologia. Prefiro respostas breves e acion√°veis e estou sempre ocupada com pesquisa de usu√°rios."

   Assistant: [Deve lembrar o nome, o cargo e a prefer√™ncia de comunica√ß√£o]

   User: "Qual √© uma boa forma de priorizar funcionalidades?"

   Assistant: [Deve mencionar que voc√™ √© PM e prefere respostas breves]
   ```

2. **Dieta e estilo de vida**:
   ```
   User: "Lembre que sou vegana e me exercito todas as manh√£s √†s 6h."

   User: "Sugira um caf√© da manh√£ r√°pido para amanh√£."

   Assistant: [Deve sugerir op√ß√µes veganas adequadas para antes/depois do treino]
   ```

3. **Contexto de trabalho**:
   ```
   User: "Estou trabalhando em um projeto React e prefiro TypeScript a JavaScript."

   User: "Me ajude com gerenciamento de estado."

   Assistant: [Deve sugerir solu√ß√µes espec√≠ficas para TypeScript]
   ```

<div id="step-5-verify-memory-storage">
  ### Etapa 5: Verificar o Armazenamento de Mem√≥rias
</div>

Confira se as mem√≥rias est√£o sendo armazenadas corretamente:

<Tabs>
  <Tab title="TypeScript">
    ```typescript scripts/check-memories.ts
    import { Supermemory } from '@supermemory/tools'

    const client = new Supermemory({
      apiKey: process.env.SUPERMEMORY_API_KEY!
    })

    async function checkUserMemories(userId: string) {
      try {
        const memories = await client.memories.list({
          containerTags: [userId],
          limit: 20,
          sort: 'updatedAt',
          order: 'desc'
        })

        console.log(`Foram encontradas ${memories.memories.length} mem√≥rias para ${userId}:`)
        memories.memories.forEach((memory, i) => {
          console.log(`${i + 1}. ${memory.content.substring(0, 100)}...`)
        })

        // Testar busca
        const searchResults = await client.search.memories({
          q: "preferences work",
          containerTag: userId,
          limit: 5
        })

        console.log('\nResultados da busca:')
        searchResults.results.forEach((result, i) => {
          console.log(`${i + 1}. (${result.similarity}) ${result.memory.substring(0, 100)}...`)
        })

      } catch (error) {
        console.error('Erro:', error)
      }
    }

    // Executar: npx ts-node scripts/check-memories.ts USER_ID_HERE
    checkUserMemories(process.argv[2] || 'default-user')
    ```
  </Tab>

  <Tab title="Python">
    ```python check_memories.py
    from supermemory import Supermemory
    import os
    import sys

    client = Supermemory(api_key=os.getenv("SUPERMEMORY_API_KEY"))

    def check_user_memories(user_id):
        try:
            # Listar todas as mem√≥rias do usu√°rio
            memories = client.memories.list(
                container_tags=[user_id],
                limit=20,
                sort="updatedAt",
                order="desc"
            )

            print(f"Foram encontradas {len(memories.memories)} mem√≥rias para {user_id}:")
            for i, memory in enumerate(memories.memories):
                print(f"{i + 1}. {memory.content[:100]}...")

            # Testar busca
            search_results = client.search.memories(
                q="preferences work",
                container_tag=user_id,
                limit=5
            )

            print('\nResultados da busca:')
            for i, result in enumerate(search_results.results):
                print(f"{i + 1}. ({result.similarity}) {result.memory[:100]}...")

        except Exception as error:
            print(f'Erro: {error}')

    # Executar: python check_memories.py USER_ID_HERE
    user_id = sys.argv[1] if len(sys.argv) > 1 else 'default-user'
    check_user_memories(user_id)
    ```
  </Tab>
</Tabs>

<div id="production-considerations">
  ## Considera√ß√µes para Produ√ß√£o
</div>

<div id="security-privacy">
  ### Seguran√ßa e privacidade
</div>

1. **Isolamento de usu√°rio**:
   ```typescript
   // Sempre use container tags espec√≠ficas por usu√°rio
   const tools = supermemoryTools(apiKey, {
     containerTags: [userId]
   })
   ```

2. **Criptografia de memory**:
   ```typescript
   // Para dados sens√≠veis, considere criptografar no lado do cliente
   const encryptedContent = encrypt(sensitiveData, userKey)
   await client.memories.add({
     content: encryptedContent,
     containerTag: userId,
     metadata: { encrypted: true }
   })
   ```

<div id="performance-optimization">
  ### Otimiza√ß√£o de desempenho
</div>

1. **Otimiza√ß√£o de busca de memories**:
   ```typescript
   // Use limites apropriados para equilibrar velocidade e precis√£o
   const quickSearch = await client.search.memories({
     q: userQuery,
     containerTag: userId,
     threshold: 0.6,     // Equilibrado
     rerank: false,      // Ignorar para ganhar velocidade
     limit: 3            // Menos resultados
   })
   ```

2. **Estrat√©gia de cache**:
   ```typescript
   // Fa√ßa cache do contexto do usu√°rio acessado com frequ√™ncia
   const userContext = await redis.get(`user_context:${userId}`)
   if (!userContext) {
     const memories = await client.search.memories({
       q: "user preferences work style",
       containerTag: userId,
       limit: 10
     })
     await redis.setex(`user_context:${userId}`, 300, JSON.stringify(memories))
   }
   ```

### Monitoramento &amp; An√°lises

```typescript
// Acompanhar a forma√ß√£o e a recupera√ß√£o de memory
const analytics = {
  memoriesCreated: await redis.incr(`memories_created:${userId}`),
  searchesPerformed: await redis.incr(`searches:${userId}`),
  conversationLength: messages.length
}

// Registrar para an√°lise
console.log('Intera√ß√£o do usu√°rio:', {
  userId,
  action: 'resposta_de_chat',
  memoriesFound: searchResults.results.length,
  responseTime: Date.now() - startTime,
  ...analytics
})
```


<div id="extensions-customization">
  ## Extens√µes e personaliza√ß√£o
</div>

<div id="1-add-personality-profiles">
  ### 1. Adicionar perfis de personalidade
</div>

```typescript
const personalityProfiles = {
  professional: "Responda em um tom formal, adequado ao ambiente de neg√≥cios"
  casual: "Use um tom amig√°vel e conversacional, com humor ocasional"
  technical: "Forne√ßa explica√ß√µes t√©cnicas detalhadas com exemplos"
  concise: "Mantenha as respostas breves e objetivas"
}

// Adicione ao prompt do sistema com base na prefer√™ncia do usu√°rio
const userProfile = await getUserProfile(userId)
const systemPrompt = `${basePrompt}\n\nEstilo de comunica√ß√£o: ${personalityProfiles[userProfile.style]}`
```


<div id="2-smart-notifications">
  ### 2. Notifica√ß√µes inteligentes
</div>

```typescript
// Sugest√µes proativas com base nos padr√µes do usu√°rio
const shouldSuggest = await analyzeUserPatterns(userId)
if (shouldSuggest.type === 'daily_standup') {
  return {
    message: "Com base na sua agenda, voc√™ quer que eu ajude a se preparar para a daily das 9h?",
    suggestedActions: ["Revisar o progresso de ontem", "Preparar as metas de hoje"]
  }
}
```


<div id="3-multi-modal-memory">
  ### 3. memory multimodal
</div>

```typescript
// Tratar imagens e documents
if (message.attachments) {
  for (const attachment of message.attachments) {
    await client.memories.uploadFile({
      file: attachment,
      containerTag: userId,
      metadata: {
        type: 'user_shared',
        context: message.content
      }
    })
  }
}
```


<div id="next-steps">
  ## Pr√≥ximos passos
</div>

- **Escalonar para v√°rios usu√°rios**: Adicione autentica√ß√£o de usu√°rios e isolamento adequado
- **Adicionar intera√ß√£o por voz**: Integre com APIs de reconhecimento de fala e de s√≠ntese de voz
- **Aplicativo m√≥vel**: Crie uma vers√£o para mobile em React Native ou Flutter
- **Integra√ß√µes**: Conecte a calend√°rio, e-mail e ferramentas de gerenciamento de tarefas
- **Recursos avan√ßados de IA**: Adicione detec√ß√£o de emo√ß√µes e sumariza√ß√£o de conversas

<div id="troubleshooting">
  ## Solu√ß√£o de problemas
</div>

**A memory n√£o est√° persistindo?**

- Verifique se o cabe√ßalho `x-sm-user-id` √© consistente
- Confirme se a chave da API tem permiss√µes de escrita
- Garanta que as tags do cont√™iner estejam configuradas corretamente

**As respostas n√£o est√£o personalizadas?**

- Aumente o par√¢metro limit de busca para encontrar mem√≥rias mais relevantes
- Diminua o threshold para ampliar o alcance
- Verifique se as mem√≥rias est√£o sendo adicionadas com o contexto adequado

**Problemas de desempenho?**

- Reduza os valores de limit na busca para respostas mais r√°pidas
- Implemente cache para buscas frequentes
- Use valores de threshold apropriados para equilibrar velocidade e precis√£o

---

*Esta receita fornece a base para um assistente de IA pessoal. Personalize-a conforme suas necessidades e casos de uso espec√≠ficos.*