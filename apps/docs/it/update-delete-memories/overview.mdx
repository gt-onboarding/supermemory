---
title: "Aggiorna ed elimina le stored memory"
description: "Aggiorna ed elimina le stored memory in modo sicuro con pattern di upsert e idempotenza"
icon: "delete"
---

Scegli tra aggiornamenti diretti, upsert idempotenti, eliminazioni singole e potenti operazioni in blocco.

<div id="direct-updates">
  ## Aggiornamenti diretti
</div>

Aggiorna le memory esistenti tramite il loro ID quando sai esattamente quale memory vuoi modificare. Le modifiche attivano il rielaboramento attraverso l’intera pipeline.

<CodeGroup>

```typescript Typescript
import Supermemory from 'supermemory';

const client = new Supermemory({
  apiKey: process.env.SUPERMEMORY_API_KEY!
});

// Update by memory ID
const updated = await client.memories.update('memory_id_123', {
  content: 'Updated content here',
  metadata: { version: 2, updated: true }
});

console.log(updated.status); // "queued" for reprocessing
console.log(updated.id); // "memory_id_123"
```

```python Python
from supermemory import Supermemory
import os

client = Supermemory(api_key=os.environ.get("SUPERMEMORY_API_KEY"))

# Update by memory ID
updated = client.memories.update(
    'memory_id_123',
    content='Updated content here',
    metadata={'version': 2, 'updated': True}
)

print(f"Status: {updated.status}")  # "queued" for reprocessing
print(f"ID: {updated.id}")  # "memory_id_123"
```

```bash cURL
curl -X PATCH "https://api.supermemory.ai/v3/documents/memory_id_123" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Updated content here",
    "metadata": {"version": 2, "updated": true}
  }'
```

</CodeGroup>

<div id="upserts-using-customid">
  ## Upsert con customId
</div>

Usa `customId` per operazioni idempotenti: lo stesso `customId` con `add()` aggiorna la memory esistente invece di crearne dei duplicati.

<CodeGroup>

```typescript Typescript
import Supermemory from 'supermemory';

const client = new Supermemory({
  apiKey: process.env.SUPERMEMORY_API_KEY!
});

const customId = 'user-note-001';

// La prima chiamata crea la memory
const created = await client.memories.add({
  content: 'Initial content',
  customId: customId,
  metadata: { version: 1 }
});

console.log('Memory creata:', created.id);

// La seconda chiamata con lo stesso customId aggiorna quella esistente
const updated = await client.memories.add({
  content: 'Updated content',
  customId: customId,         // Same customId = upsert
  metadata: { version: 2 }
});
```

```python Python
from supermemory import Supermemory
import os

client = Supermemory(api_key=os.environ.get("SUPERMEMORY_API_KEY"))

custom_id = 'user-note-001'

# La prima chiamata crea la memory
created = client.memories.add(
    content='Initial content',
    custom_id=custom_id,
    metadata={'version': 1}
)

print(f'Memory creata: {created.id}')

# La seconda chiamata con lo stesso customId aggiorna quella esistente
updated = client.memories.add(
    content='Updated content',
    custom_id=custom_id,     # Same customId = upsert
    metadata={'version': 2}
)

print(f'Memory aggiornata: {updated.id}')
print(f'Stessa memory? {created.id == updated.id}')  # True
```

```bash cURL
# Prima chiamata - crea la memory
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Initial content",
    "customId": "user-note-001",
    "metadata": {"version": 1}
  }'

# Response: {"id": "mem_abc123", "status": "queued", "customId": "user-note-001"}

# Seconda chiamata - aggiorna l'esistente (stesso customId)
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Updated content",
    "customId": "user-note-001",
    "metadata": {"version": 2}
  }'

# Response: {"id": "mem_abc123", "status": "queued", "customId": "user-note-001"}
# Nota: viene restituito lo stesso id - la memory è stata aggiornata, non creata
```

</CodeGroup>

<Note>
Il `customId` abilita l’idempotenza su tutti gli endpoint. Il `memoryId` non la supporta: solo il `customId` supporta l’idempotenza.
</Note>

<div id="single-delete">
  ## Eliminazione singola
</div>

Elimina singole memory tramite il loro id. Si tratta di un'eliminazione definitiva senza possibilità di recupero.

<CodeGroup>

```typescript Typescript
// Hard delete - rimuove definitivamente la memory
await client.memories.delete('memory_id_123');
console.log('Memory eliminata con successo');
```

```python Python
# Hard delete - rimuove definitivamente la memory
client.memories.delete('memory_id_123')
print('Memory eliminata con successo')

# Gestione degli errori per l'eliminazione singola
try:
    client.memories.delete('memory_id_123')
    print('Eliminazione riuscita')
except NotFoundError:
    print('Memory non trovata o già eliminata')
except AuthenticationError:
    print('Autenticazione non riuscita')
except Exception as e:
    print(f'Eliminazione non riuscita: {e}')
```

```bash cURL
curl -X DELETE "https://api.supermemory.ai/v3/documents/memory_id_123" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY"

# Response: 204 No Content (successo)
# Response: 404 Not Found (la memory non esiste)
```

</CodeGroup>

<div id="bulk-delete-by-ids">
  ## Eliminazione in blocco per ID
</div>

Elimina più memory in una volta fornendo un array di ID di memory. Massimo 100 ID per richiesta.

<CodeGroup>

```typescript Typescript
// Eliminazione in blocco per ID di memory
const result = await client.memories.bulkDelete({
  ids: [
    'memory_id_1',
    'memory_id_2',
    'memory_id__3',
    'non_existent_id'  // Questo verrà riportato negli errori
  ]
});

console.log('Risultato dell’eliminazione in blocco:', result);
// Output: {
//   success: true,
//   deletedCount: 3,
//   errors: [
//     { id: "non_existent_id", error: "Memory not found" }
//   ]
// }
```

```python Python
# Eliminazione in blocco per ID di memory
result = client.memories.bulk_delete(
    ids=[
        'memory_id_1',
        'memory_id_2',
        'memory_id_3',
        'non_existent_id'  # Questo verrà riportato negli errori
    ]
)

print(f'Risultato dell’eliminazione in blocco: {result}')
# Output: {
#   'success': True,
#   'deletedCount': 3,
#   'errors': [
#     {'id': 'non_existent_id', 'error': 'Memory not found'}
#   ]
# }
```

```bash cURL
curl -X DELETE "https://api.supermemory.ai/v3/documents/bulk" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "ids": [
      "memory_id_1",
      "memory_id_2",
      "memory_id_3",
      "non_existent_id"
    ]
  }'

# Risposta: {
#   "success": true,
#   "deletedCount": 3,
#   "errors": [
#     {"id": "non_existent_id", "error": "Memory not found"}
#   ]
# }
```

</CodeGroup>

<div id="bulk-delete-by-container-tags">
  ## Eliminazione in blocco per container tag
</div>

Elimina tutte le memory all'interno di specifici container tag. Utile per ripulire interi progetti o dati utente.

<CodeGroup>

```typescript Typescript
// Elimina tutte le memory in specifici container tag
const result = await client.memories.bulkDelete({
  containerTags: ['user-123', 'project-old', 'archived-content']
});

console.log('Risultato eliminazione in blocco per tag:', result);
// Output: {
//   success: true,
//   deletedCount: 45,
//   containerTags: ["user-123", "project-old", "archived-content"]
// }
```

```python Python
# Elimina tutte le memory in specifici container tag
result = client.memories.bulk_delete(
    container_tags=['user-123', 'project-old', 'archived-content']
)

print(f'Risultato eliminazione in blocco per tag: {result}')
# Output: {
#   'success': True,
#   'deletedCount': 45,
//   'containerTags': ['user-123', 'project-old', 'archived-content']
# }
```

```bash cURL
curl -X DELETE "https://api.supermemory.ai/v3/documents/bulk" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "containerTags": ["user-123", "project-old", "archived-content"]
  }'

# Risposta: {
#   "success": true,
#   "deletedCount": 45,
#   "containerTags": ["user-123", "project-old", "archived-content"]
# }
```

</CodeGroup>

<div id="advanced-patterns">
  ## Pattern avanzati
</div>

<div id="soft-delete-implementation">
  ### Implementazione del soft delete
</div>

Per le applicazioni che richiedono audit trail o meccanismi di ripristino, implementa pattern di soft delete utilizzando la metadata:

<CodeGroup>

```typescript Typescript
// Pattern di soft delete con metadata
await client.memories.update('memory_id', {
  metadata: {
    deleted: true,
    deletedAt: new Date().toISOString(),
    deletedBy: 'user_123'
  }
});

// Escludi le memory eliminate nelle ricerche
const activeMemories = await client.memories.list({
  filters: JSON.stringify({
    AND: [
      { key: "deleted", value: "true", negate: true }
    ]
  })
});

console.log('Memory attive:', activeMemories.results.length);
```

```python Python
from datetime import datetime
import json

# Pattern di soft delete con metadata
client.memories.update('memory_id', {
    'metadata': {
        'deleted': True,
        'deletedAt': datetime.now().isoformat(),
        'deletedBy': 'user_123'
    }
})

# Escludi le memory eliminate
active_memories = client.memories.list(
    filters=json.dumps({
        "AND": [
            {"key": "deleted", "value": "true", "negate": True}
        ]
    })
)

print(f'Memory attive: {len(active_memories.results)}')
```

```bash cURL
# Soft delete con metadata
curl -X PATCH "https://api.supermemory.ai/v3/documents/memory_id" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "metadata": {
      "deleted": true,
      "deletedAt": "2024-01-15T10:30:00Z",
      "deletedBy": "user_123"
    }
  }'

# Response: {"id": "memory_id", "status": "queued"}
```

</CodeGroup>

<div id="batch-processing-for-large-operations">
  ### Elaborazione in batch per operazioni di grandi dimensioni
</div>

<CodeGroup>

```typescript Typescript
// Elimina in batch in modo sicuro grandi quantità di memory
async function batchDeleteMemories(memoryIds: string[], batchSize = 100) {
  const results = [];

  for (let i = 0; i < memoryIds.length; i += batchSize) {
    const batch = memoryIds.slice(i, i + batchSize);

    console.log(`Elaborazione batch ${Math.floor(i/batchSize) + 1} di ${Math.ceil(memoryIds.length/batchSize)}`);

    try {
      const result = await client.memories.bulkDelete({ ids: batch });
      results.push(result);

      // Breve pausa tra i batch per evitare il rate limiting
      if (i + batchSize < memoryIds.length) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    } catch (error) {
      console.error(`Batch ${Math.floor(i/batchSize) + 1} non riuscito:`, error);
      results.push({ success: false, error: error.message, batch });
    }
  }

  // Aggrega i risultati
  const totalDeleted = results
    .filter(r => r.success)
    .reduce((sum, r) => sum + (r.deletedCount || 0), 0);

  console.log(`Totale eliminato: ${totalDeleted} su ${memoryIds.length}`);
  return { totalDeleted, results };
}
```

```python Python
import time
import math

def batch_delete_memories(memory_ids, batch_size=100):
    """Elimina in batch in modo sicuro grandi quantità di memory"""
    results = []

    for i in range(0, len(memory_ids), batch_size):
        batch = memory_ids[i:i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = math.ceil(len(memory_ids) / batch_size)

        print(f'Elaborazione batch {batch_num} di {total_batches}')

        try:
            result = client.memories.bulk_delete(ids=batch)
            results.append(result)

            # Breve pausa tra i batch per evitare il rate limiting
            if i + batch_size < len(memory_ids):
                time.sleep(1)
        except Exception as error:
            print(f'Batch {batch_num} non riuscito: {error}')
            results.append({'success': False, 'error': str(error), 'batch': batch})

    # Aggrega i risultati
    total_deleted = sum(
        r.get('deletedCount', 0) for r in results if r.get('success')
    )

    print(f'Totale eliminato: {total_deleted} su {len(memory_ids)}')
    return {'totalDeleted': total_deleted, 'results': results}
```

```bash cURL
# Esempio di script di elaborazione in batch
#!/bin/bash

MEMORY_IDS=("id1" "id2" "id3")  # Il tuo array di ID delle memory
BATCH_SIZE=100
TOTAL_DELETED=0

# Elabora in batch
for ((i=0; i<${#MEMORY_IDS[@]}; i+=BATCH_SIZE)); do
    batch=("${MEMORY_IDS[@]:i:BATCH_SIZE}")
    batch_json=$(printf '%s\n' "${batch[@]}" | jq -R . | jq -s .)

    echo "Elaborazione batch $((i/BATCH_SIZE + 1))"

    response=$(curl -s -X DELETE \
      "https://api.supermemory.ai/v3/documents/bulk" \
      -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
      -H "Content-Type: application/json" \
      -d "{\"ids\": $batch_json}")

    deleted_count=$(echo "$response" | jq -r '.deletedCount // 0')
    TOTAL_DELETED=$((TOTAL_DELETED + deleted_count))

    echo "Batch eliminato: $deleted_count memory"
    sleep 1  # Protezione dal rate limiting
done

echo "Totale eliminato: $TOTAL_DELETED memory"
```

</CodeGroup>

<div id="best-practices">
  ## Best practice consigliate
</div>

<div id="update-operations">
  ### Operazioni di aggiornamento
</div>

1. **Usa customId per aggiornamenti idempotenti** - Previene duplicati di memory e consente retry sicuri
2. **Monitora lo status di elaborazione** - Gli aggiornamenti avviano l’intera pipeline di rielaborazione
3. **Gestisci la metadata con attenzione** - Gli aggiornamenti sostituiscono le chiavi di metadata specificate
4. **Implementa una corretta gestione degli errori** - La memory potrebbe essere eliminata tra un’operazione e l’altra

<div id="delete-operations">
  ### Operazioni di eliminazione
</div>

1. **L'eliminazione hard è permanente** - Non esiste alcun meccanismo di ripristino
2. **Usa in modo efficiente le operazioni in blocco** - Massimo 100 id per richiesta di eliminazione in blocco
3. **Valuta il soft delete** - Usa flag nei metadata per eliminazioni recuperabili
4. **Esegui batch per operazioni di grandi dimensioni** - Evita i rate limit con un batching adeguato
5. **Pulisci lo stato dell'applicazione** - Aggiorna UI/cache dopo le eliminazioni