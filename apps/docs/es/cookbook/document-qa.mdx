---
title: "Sistema de preguntas y respuestas sobre Documentos"
description: "Crea un chatbot que responda preguntas de tus Documentos con citas y referencias de origen"
---

Crea un sistema potente de preguntas y respuestas sobre documentos que pueda incorporar PDFs, archivos de texto y páginas web, y luego responder preguntas con citas precisas. Ideal para sitios de documentación, bases de datos de investigación o bases de conocimiento internas.

<div id="what-youll-build">
  ## Qué vas a construir
</div>

Un sistema de preguntas y respuestas sobre documentos que:

- **Ingiere múltiples tipos de archivos** (PDF, DOCX, texto, URL)
- **Responde preguntas con precisión** e incluye citas de la fuente
- **Proporciona referencias de la fuente** con números de página y títulos de los documentos
- **Gestiona preguntas de seguimiento** con contexto conversacional
- **Admite múltiples colecciones de documentos** para distintos temas

<div id="prerequisites">
  ## Requisitos previos
</div>

- Node.js 18+ o Python 3.8+
- Clave de API de Supermemory
- Clave de API de OpenAI
- Conocimientos básicos sobre manejo de archivos

<div id="implementation">
  ## Implementación
</div>

<div id="step-1-document-processing-system">
  ### Paso 1: Sistema de procesamiento de documentos
</div>

<Tabs>
  <Tab title="Next.js">
    ```typescript lib/document-processor.ts
    import { Supermemory } from 'supermemory'

    const client = new Supermemory({
      apiKey: process.env.SUPERMEMORY_API_KEY!
    })

    interface DocumentUpload {
      file: File
      collection: string
      metadata?: Record<string, any>
    }

    export class DocumentProcessor {
      async uploadDocument({ file, collection, metadata = {} }: DocumentUpload) {
        try {
          const formData = new FormData()
          formData.append('file', file)
          formData.append('containerTags', JSON.stringify([collection]))
          formData.append('metadata', JSON.stringify({
            originalName: file.name,
            fileType: file.type,
            uploadedAt: new Date().toISOString(),
            ...metadata
          }))

          const response = await fetch('/api/upload-document', {
            method: 'POST',
            body: formData
          })

          if (!response.ok) {
            throw new Error(`Error de carga: ${response.statusText}`)
          }

          return await response.json()
        } catch (error) {
          console.error('Error al cargar el documento:', error)
          throw error
        }
      }

      async uploadURL({ url, collection, metadata = {} }: { url: string, collection: string, metadata?: Record<string, any> }) {
        try {
          const result = await client.memories.add({
            content: url,
            containerTag: collection,
            metadata: {
              type: 'url',
              originalUrl: url,
              uploadedAt: new Date().toISOString(),
              ...metadata
            }
          })

          return result
        } catch (error) {
          console.error('Error al cargar la URL:', error)
          throw error
        }
      }

      async getDocumentStatus(documentId: string) {
        try {
          const memory = await client.memories.get(documentId)
          return {
            id: memory.id,
            status: memory.status,
            title: memory.title,
            progress: memory.metadata?.progress || 0
          }
        } catch (error) {
          console.error('Error al comprobar el estado:', error)
          throw error
        }
      }

      async listDocuments(collection: string) {
        try {
          const memories = await client.memories.list({
            containerTags: [collection],
            limit: 50,
            sort: 'updatedAt',
            order: 'desc'
          })

          return memories.memories.map(memory => ({
            id: memory.id,
            title: memory.title || memory.metadata?.originalName || 'Sin título',
            type: memory.metadata?.fileType || memory.metadata?.type || 'desconocido',
            uploadedAt: memory.metadata?.uploadedAt,
            status: memory.status,
            url: memory.metadata?.originalUrl
          }))
        } catch (error) {
          console.error('Error al listar documentos:', error)
          throw error
        }
      }
    }
    ```

    ```typescript app/api/upload-document/route.ts
    import { NextRequest, NextResponse } from 'next/server'
    import { Supermemory } from 'supermemory'

    const client = new Supermemory({
      apiKey: process.env.SUPERMEMORY_API_KEY!
    })

    export async function POST(request: NextRequest) {
      try {
        const formData = await request.formData()
        const file = formData.get('file') as File
        const containerTags = JSON.parse(formData.get('containerTags') as string)
        const metadata = JSON.parse(formData.get('metadata') as string || '{}')

        if (!file) {
          return NextResponse.json({ error: 'No se proporcionó archivo' }, { status: 400 })
        }

        // Convertir File a Buffer para Supermemory
        const bytes = await file.arrayBuffer()
        const buffer = Buffer.from(bytes)

        const result = await client.memories.uploadFile({
          file: buffer,
          filename: file.name,
          containerTags,
          metadata
        })

        return NextResponse.json({
          success: true,
          documentId: result.id,
          message: 'Documento cargado exitosamente'
        })

      } catch (error) {
        console.error('Error de carga:', error)
        return NextResponse.json(
          { error: 'Error en la carga', details: error.message },
          { status: 500 }
        )
      }
    }
    ```
  </Tab>

  <Tab title="Python">
    ```python document_processor.py
    from supermemory import Supermemory
    import os
    from typing import Dict, List, Any, Optional
    import requests
    from datetime import datetime

    class DocumentProcessor:
        def __init__(self):
            self.client = Supermemory(api_key=os.getenv("SUPERMEMORY_API_KEY"))

        def upload_file(self, file_path: str, collection: str, metadata: Dict[str, Any] = None) -> Dict:
            """Cargar un archivo local a Supermemory"""
            if metadata is None:
                metadata = {}

            try:
                with open(file_path, 'rb') as file:
                    result = self.client.memories.upload_file(
                        file=file,
                        container_tags=[collection],
                        metadata={
                            'originalName': os.path.basename(file_path),
                            'fileType': os.path.splitext(file_path)[1],
                            'uploadedAt': datetime.now().isoformat(),
                            **metadata
                        }
                    )
                return result
            except Exception as e:
                print(f"Error al cargar archivo: {e}")
                raise

        def upload_url(self, url: str, collection: str, metadata: Dict[str, Any] = None) -> Dict:
            """Cargar contenido de URL a Supermemory"""
            if metadata is None:
                metadata = {}

            try:
                result = self.client.memories.add(
                    content=url,
                    container_tag=collection,
                    metadata={
                        'type': 'url',
                        'originalUrl': url,
                        'uploadedAt': datetime.now().isoformat(),
                        **metadata
                    }
                )
                return result
            except Exception as e:
                print(f"Error al cargar URL: {e}")
                raise

        def get_document_status(self, document_id: str) -> Dict:
            """Verificar el estado de procesamiento del documento"""
            try:
                memory = self.client.memories.get(document_id)
                return {
                    'id': memory.id,
                    'status': memory.status,
                    'title': memory.title,
                    'progress': memory.metadata.get('progress', 0) if memory.metadata else 0
                }
            except Exception as e:
                print(f"Error al verificar estado: {e}")
                raise

        def list_documents(self, collection: str) -> List[Dict]:
            """Listar todos los documentos en una colección"""
            try:
                memories = self.client.memories.list(
                    container_tags=[collection],
                    limit=50,
                    sort='updatedAt',
                    order='desc'
                )

                return [
                    {
                        'id': memory.id,
                        'title': (memory.title or
                                memory.metadata.get('originalName') or
                                'Sin título' if memory.metadata else 'Sin título'),
                        'type': (memory.metadata.get('fileType') or
                               memory.metadata.get('type') or
                               'desconocido' if memory.metadata else 'desconocido'),
                        'uploadedAt': memory.metadata.get('uploadedAt') if memory.metadata else None,
                        'status': memory.status,
                        'url': memory.metadata.get('originalUrl') if memory.metadata else None
                    }
                    for memory in memories.memories
                ]
            except Exception as e:
                print(f"Error al listar documentos: {e}")
                raise
    ```
  </Tab>
</Tabs>

<div id="step-2-qa-api-with-citations">
  ### Paso 2: API de preguntas y respuestas con citas
</div>

<Tabs>
  <Tab title="Ruta de API en Next.js">
    ```typescript app/api/qa/route.ts
    import { streamText } from 'ai'
    import { createOpenAI } from '@ai-sdk/openai'
    import { Supermemory } from 'supermemory'

    const openai = createOpenAI({
      apiKey: process.env.OPENAI_API_KEY!
    })

    const client = new Supermemory({
      apiKey: process.env.SUPERMEMORY_API_KEY!
    })

    export async function POST(request: Request) {
      const { question, collection, conversationHistory = [] } = await request.json()

      try {
        // Buscar documentos relevantes
        const searchResults = await client.search.documents({
          q: question,
          containerTags: [collection],
          limit: 8,
          rerank: true,
          includeFullDocs: false,
          includeSummary: true,
          onlyMatchingChunks: false,
          documentThreshold: 0.6,
          chunkThreshold: 0.7
        })

        if (searchResults.results.length === 0) {
          return Response.json({
            answer: "No pude encontrar información relevante en los documentos cargados para responder tu pregunta.",
            sources: [],
            confidence: 0
          })
        }

        // Preparar contexto a partir de los resultados de búsqueda
        const context = searchResults.results.map((result, index) => {
          const chunks = result.chunks
            .filter(chunk => chunk.isRelevant)
            .slice(0, 3)
            .map(chunk => chunk.content)
            .join('\n\n')

          return `[Documento ${index + 1}: "${result.title}"]\n${chunks}`
        }).join('\n\n---\n\n')

        // Preparar fuentes para citación
        const sources = searchResults.results.map((result, index) => ({
          id: result.documentId,
          title: result.title,
          type: result.type,
          relevantChunks: result.chunks.filter(chunk => chunk.isRelevant).length,
          score: result.score,
          citationNumber: index + 1
        }))

        const messages = [
          ...conversationHistory,
          {
            role: 'user' as const,
            content: question
          }
        ]

        const result = await streamText({
          model: openai('gpt-5'),
          messages,
          system: `Eres un asistente útil de preguntas y respuestas sobre documentos. Responde preguntas basándote ÚNICAMENTE en el contexto de documentos proporcionado.

    CONTEXTO DE LOS DOCUMENTOS:
    ${context}

    INSTRUCCIONES:
    1. Responde la pregunta usando ÚNICAMENTE la información de los documentos proporcionados
    2. Incluye citas específicas en tu respuesta usando el formato [Documento X]
    3. Si los documentos no contienen suficiente información, dilo claramente
    4. Sé preciso y cita directamente cuando sea posible
    5. Si múltiples documentos respaldan un punto, cita todos los relevantes
    6. Mantén un tono útil y profesional

    FORMATO DE CITACIÓN:
    - Usa [Documento 1], [Documento 2], etc. para citar fuentes
    - Coloca las citas después de la información relevante
    - Ejemplo: "El proceso involucra tres pasos [Documento 1]. Sin embargo, algunos expertos recomiendan un enfoque de cuatro pasos [Documento 3]."

    Si la pregunta no puede ser respondida con los documentos proporcionados, responde con: "No tengo suficiente información en los documentos proporcionados para responder esta pregunta con precisión."`,
          temperature: 0.1,
          maxTokens: 1000
        })

        return result.toAIStreamResponse({
          data: {
            sources,
            searchResultsCount: searchResults.results.length,
            totalResults: searchResults.total
          }
        })

      } catch (error) {
        console.error('Error de Q&A:', error)
        return Response.json(
          { error: 'Error al procesar la pregunta', details: error.message },
          { status: 500 }
        )
      }
    }
    ```
  </Tab>

  <Tab title="Python FastAPI">
    ```python qa_api.py
    from fastapi import FastAPI, HTTPException
    from fastapi.responses import StreamingResponse
    from pydantic import BaseModel
    from typing import List, Dict, Any, Optional
    import openai
    from supermemory import Supermemory
    import json
    import os

    app = FastAPI()

    openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    supermemory_client = Supermemory(api_key=os.getenv("SUPERMEMORY_API_KEY"))

    class QARequest(BaseModel):
        question: str
        collection: str
        conversationHistory: List[Dict[str, str]] = []

    class QAResponse(BaseModel):
        answer: str
        sources: List[Dict[str, Any]]
        confidence: float
        searchResultsCount: int

    @app.post("/qa")
    async def answer_question(request: QARequest):
        try:
            # Buscar documentos pertinentes
            search_results = supermemory_client.search.documents(
                q=request.question,
                container_tags=[request.collection],
                limit=8,
                rerank=True,
                include_full_docs=False,
                include_summary=True,
                only_matching_chunks=False,
                document_threshold=0.6,
                chunk_threshold=0.7
            )

            if not search_results.results:
                return QAResponse(
                    answer="No encontré información relevante en los documentos cargados para responder a tu pregunta.",
                    sources=[],
                    confidence=0,
                    searchResultsCount=0
                )

            # Preparar el contexto a partir de los resultados de la búsqueda
            context_parts = []
            sources = []

            for index, result in enumerate(search_results.results):
                relevant_chunks = [
                    chunk.content for chunk in result.chunks
                    if chunk.is_relevant
                ][:3]

                chunk_text = '\n\n'.join(relevant_chunks)
                context_parts.append(f'[Document {index + 1}: "{result.title}"]\n{chunk_text}')

                sources.append({
                    'id': result.document_id,
                    'title': result.title,
                    'type': result.type,
                    'relevantChunks': len([c for c in result.chunks if c.is_relevant]),
                    'score': result.score,
                    'citationNumber': index + 1
                })

            context = '\n\n---\n\n'.join(context_parts)

            # Prepare messages
            messages = [
                {
                    "role": "system",
                    "content": f"""Eres un asistente útil de preguntas y respuestas sobre documentos. Responde preguntas SOLO en función del contexto de los documentos proporcionado.

    CONTEXTO DE LOS DOCUMENTOS:
    {context}

    INSTRUCCIONES:
    1. Responde la pregunta usando SOLO la información de los documentos proporcionados
    2. Incluye citas específicas en tu respuesta usando el formato [Document X]
    3. Si los documentos no contienen suficiente información, indícalo claramente
    4. Sé preciso y cita textualmente cuando sea posible
    5. Si varios documentos respaldan un punto, cita todos los relevantes
    6. Mantén un tono servicial y profesional

    FORMATO DE CITAS:
    - Usa [Document 1], [Document 2], etc., para citar fuentes
    - Coloca las citas después de la información pertinente
    - Ejemplo: "El proceso consta de tres pasos [Document 1]. Sin embargo, algunos expertos recomiendan un enfoque de cuatro pasos [Document 3]."

    Si la pregunta no puede responderse con los documentos proporcionados, responde con: "No tengo suficiente información en los documentos proporcionados para responder esta pregunta con precisión." """
                }
            ]

            # Agregar el historial de conversación
            messages.extend(request.conversationHistory)
            messages.append({"role": "user", "content": request.question})

            # Obtener la respuesta de la IA
            response = await openai_client.chat.completions.create(
                model="gpt-5",
                messages=messages,
                temperature=0.1,
                max_tokens=1000
            )

            answer = response.choices[0].message.content

            return QAResponse(
                answer=answer,
                sources=sources,
                confidence=min(search_results.results[0].score if search_results.results else 0, 1.0),
                searchResultsCount=len(search_results.results)
            )

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"No se pudo procesar la pregunta: {str(e)}")

    if __name__ == "__main__":
        import uvicorn
        uvicorn.run(app, host="0.0.0.0", port=8000)
    ```
  </Tab>
</Tabs>

<div id="step-3-frontend-interface">
  ### Paso 3: Interfaz de frontend
</div>

```tsx app/qa/page.tsx
'use client'

import { useState, useRef } from 'react'
import { useChat } from 'ai/react'
import { DocumentProcessor } from '@/lib/document-processor'

interface Document {
  id: string
  title: string
  type: string
  status: string
  uploadedAt: string
}

interface Source {
  id: string
  title: string
  citationNumber: number
  score: number
  relevantChunks: number
}

export default function DocumentQA() {
  const [collection, setCollection] = useState('default-docs')
  const [documents, setDocuments] = useState<Document[]>([])
  const [sources, setSources] = useState<Source[]>([])
  const [isUploading, setIsUploading] = useState(false)
  const [uploadProgress, setUploadProgress] = useState<Record<string, number>>({})
  const fileInputRef = useRef<HTMLInputElement>(null)

  const processor = new DocumentProcessor()

  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: '/api/qa',
    body: {
      collection
    },
    onFinish: (message, { data }) => {
      if (data?.sources) {
        setSources(data.sources)
      }
    }
  })

  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files
    if (!files || files.length === 0) return

    setIsUploading(true)
    const newProgress: Record<string, number> = {}

    try {
      for (const file of Array.from(files)) {
        newProgress[file.name] = 0
        setUploadProgress({ ...newProgress })

        await processor.uploadDocument({
          file,
          collection,
          metadata: {
            uploadedBy: 'user',
            category: 'qa-document'
          }
        })

        newProgress[file.name] = 100
        setUploadProgress({ ...newProgress })
      }

      // Refresh document list
      await loadDocuments()

      // Clear file input
      if (fileInputRef.current) {
        fileInputRef.current.value = ''
      }

    } catch (error) {
      console.error('Upload failed:', error)
      alert('Upload failed: ' + error.message)
    } finally {
      setIsUploading(false)
      setUploadProgress({})
    }
  }

  const loadDocuments = async () => {
    try {
      const docs = await processor.listDocuments(collection)
      setDocuments(docs)
    } catch (error) {
      console.error('Failed to load documents:', error)
    }
  }

  const formatSources = (sources: Source[]) => {
    if (!sources || sources.length === 0) return null

    return (
      <div className="mt-4 p-4 bg-gray-50 border border-gray-200 rounded-lg">
        <h3 className="text-sm font-semibold text-gray-700 mb-2">Sources:</h3>
        <div className="space-y-2">
          {sources.map((source) => (
            <div key={source.id} className="flex items-center space-x-2 text-sm">
              <span className="bg-blue-100 text-blue-800 px-2 py-1 rounded text-xs font-mono">
                Document {source.citationNumber}
              </span>
              <span className="text-gray-700">{source.title}</span>
              <span className="text-gray-500">
                ({source.relevantChunks} relevant chunks, {(source.score * 100).toFixed(1)}% match)
              </span>
            </div>
          ))}
        </div>
      </div>
    )
  }

  return (
    <div className="max-w-6xl mx-auto p-6">
      <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
        {/* Panel de Gestión de Documentos */}
        <div className="lg:col-span-1">
          <div className="bg-white border border-gray-200 rounded-lg p-6">
            <h2 className="text-lg font-semibold mb-4">Colección de Documentos</h2>

            {/* Selector de Colección */}
            <div className="mb-4">
              <label className="block text-sm font-medium text-gray-700 mb-2">
                Nombre de la Colección
              </label>
              <input
                type="text"
                value={collection}
                onChange={(e) => setCollection(e.target.value)}
                className="w-full p-2 border border-gray-300 rounded focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
                placeholder="ej., docs-empresa"
              />
            </div>

            {/* Carga de Archivos */}
            <div className="mb-4">
              <input
                ref={fileInputRef}
                type="file"
                multiple
                accept=".pdf,.docx,.txt,.md"
                onChange={handleFileUpload}
                className="hidden"
              />
              <button
                onClick={() => fileInputRef.current?.click()}
                disabled={isUploading}
                className="w-full p-3 border-2 border-dashed border-gray-300 rounded-lg hover:border-blue-400 focus:ring-2 focus:ring-blue-500 disabled:opacity-50"
              >
                {isUploading ? 'Cargando...' : 'Cargar Documentos'}
              </button>
            </div>

            {/* Progreso de Carga */}
            {Object.keys(uploadProgress).length > 0 && (
              <div className="mb-4 space-y-2">
                {Object.entries(uploadProgress).map(([filename, progress]) => (
                  <div key={filename} className="text-sm">
                    <div className="flex justify-between">
                      <span className="truncate">{filename}</span>
                      <span>{progress}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div
                        className="bg-blue-600 h-2 rounded-full transition-all duration-300"
                        style={{ width: `${progress}%` }}
                      />
                    </div>
                  </div>
                ))}
              </div>
            )}

            {/* Lista de Documentos */}
            <div className="max-h-64 overflow-y-auto">
              {documents.map((doc) => (
                <div key={doc.id} className="mb-2 p-2 bg-gray-50 rounded text-sm">
                  <div className="font-medium truncate">{doc.title}</div>
                  <div className="text-gray-500 text-xs">
                    {doc.type} • {doc.status}
                  </div>
                </div>
              ))}
            </div>

            <button
              onClick={loadDocuments}
              className="w-full mt-4 px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
            >
              Actualizar Documentos
            </button>
          </div>
        </div>

        {/* Interfaz de Preguntas y Respuestas */}
        <div className="lg:col-span-2">
          <div className="bg-white border border-gray-200 rounded-lg p-6">
            <h2 className="text-lg font-semibold mb-4">Hacer Preguntas</h2>

            {/* Mensajes */}
            <div className="h-96 overflow-y-auto mb-4 space-y-4">
              {messages.length === 0 && (
                <div className="text-gray-500 text-center py-8">
                  ¡Carga documentos y haz preguntas para empezar!

                  <div className="mt-4 text-sm">
                    <p className="font-medium">Prueba preguntando:</p>
                    <ul className="mt-2 space-y-1">
                      <li>"¿Cuáles son los principales hallazgos?"</li>
                      <li>"Resume los puntos clave"</li>
                      <li>"¿Qué dice la sección 3 sobre...?"</li>
                    </ul>
                  </div>
                </div>
              )}

              {messages.map((message) => (
                <div
                  key={message.id}
                  className={`p-4 rounded-lg ${
                    message.role === 'user'
                      ? 'bg-blue-500 text-white ml-8'
                      : 'bg-gray-100 mr-8'
                  }`}
                >
                  <div className="whitespace-pre-wrap">{message.content}</div>

                  {message.role === 'assistant' && sources.length > 0 && (
                    formatSources(sources)
                  )}
                </div>
              ))}

              {isLoading && (
                <div className="bg-gray-100 p-4 rounded-lg mr-8">
                  <div className="flex items-center space-x-2">
                    <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-600"></div>
                    <span>Buscando en documentos y generando respuesta...</span>
                  </div>
                </div>
              )}
            </div>

            {/* Input */}
            <form onSubmit={handleSubmit} className="flex gap-2">
              <input
                value={input}
                onChange={handleInputChange}
                placeholder="Haz una pregunta sobre tus documentos..."
                className="flex-1 p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
                disabled={isLoading || documents.length === 0}
              />
              <button
                type="submit"
                disabled={isLoading || !input.trim() || documents.length === 0}
                className="px-6 py-3 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50 disabled:cursor-not-allowed"
              >
                Preguntar
              </button>
            </form>

            {documents.length === 0 && (
              <p className="text-sm text-gray-500 mt-2">
                Sube documentos primero para hacer preguntas
              </p>
            )}
          </div>
        </div>
      </div>
    </div>
  )
}
```

<div id="testing-your-qa-system">
  ## Prueba de tu sistema de preguntas y respuestas
</div>

<div id="step-4-test-document-processing">
  ### Paso 4: Probar el procesamiento de Documentos
</div>

1. **Cargar Documentos de prueba**:
   - Sube un manual en PDF o un artículo de investigación
   - Agrega algunos artículos web mediante url
   - Sube algunos archivos de texto sobre distintos temas

2. **Probar tipos de preguntas**:
   ```
   Factual: "¿Cuál es la definición de X mencionada en los Documentos?"
   Analytical: "¿Cuáles son los pros y contras del enfoque Y?"
   Comparative: "¿Cómo se compara el método A con el método B?"
   Summarization: "Resume los hallazgos principales"
   ```

3. **Verificar citas**:
   - Comprueba que las citas aparezcan en las respuestas
   - Verifica que los números de cita coincidan con la lista de fuentes
   - Asegúrate de que las fuentes muestren metadata relevante

<div id="production-considerations">
  ## Consideraciones para producción
</div>

<div id="performance-optimization">
  ### Optimización del rendimiento
</div>

```typescript
// Implementar caché para preguntas frecuentes
const cacheKey = `qa:${collection}:${hashQuery(question)}`
const cachedResponse = await redis.get(cacheKey)

if (cachedResponse) {
  return JSON.parse(cachedResponse)
}

// Almacenar respuesta en caché por 1 hora
await redis.setex(cacheKey, 3600, JSON.stringify(response))
```


<div id="advanced-features">
  ### Funciones avanzadas
</div>

1. **Preguntas de seguimiento**:
   ```typescript
   // Registrar el contexto de la conversación
   const conversationHistory = messages.slice(-6) // Últimos 3 intercambios
   ```

2. **Puntuación de confianza de la respuesta**:
   ```typescript
   const confidence = calculateConfidence({
     searchScore: searchResults.results[0]?.score || 0,
     resultCount: searchResults.results.length,
     chunkRelevance: avgChunkRelevance
   })
   ```

3. **Compatibilidad multilingüe**:
   ```typescript
   // Detectar el idioma del documento y adaptar la búsqueda
   const detectedLanguage = await detectLanguage(question)
   const searchResults = await client.search.documents({
     q: question,
     filters: {
       AND: [{ key: 'language', value: detectedLanguage }]
     }
   })
   ```

Esta receta proporciona una base completa para crear sistemas de preguntas y respuestas sobre Documentos con citas precisas y seguimiento de fuentes.

---

*Personaliza esta receta según tus tipos de Documentos y casos de uso específicos.*