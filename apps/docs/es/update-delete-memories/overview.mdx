---
title: "Actualizar y eliminar memories"
description: "Actualiza y elimina memories de forma segura con upsert idempotentes e idempotencia"
icon: "delete"
---

Elige entre actualizaciones directas, upserts idempotentes, eliminaciones individuales y operaciones masivas potentes.

<div id="direct-updates">
  ## Actualizaciones directas
</div>

Actualiza memories existentes por su ID cuando ya conoces la memory específica que quieres modificar. Los cambios activan el reprocesamiento a través de todo el pipeline.

<CodeGroup>

```typescript Typescript
import Supermemory from 'supermemory';

const client = new Supermemory({
  apiKey: process.env.SUPERMEMORY_API_KEY!
});

// Update by memory ID
const updated = await client.memories.update('memory_id_123', {
  content: 'Updated content here',
  metadata: { version: 2, updated: true }
});

console.log(updated.status); // "queued" para reprocesamiento
console.log(updated.id); // "memory_id_123"
```

```python Python
from supermemory import Supermemory
import os

client = Supermemory(api_key=os.environ.get("SUPERMEMORY_API_KEY"))

# Update by memory ID
updated = client.memories.update(
    'memory_id_123',
    content='Updated content here',
    metadata={'version': 2, 'updated': True}
)

print(f"Status: {updated.status}")  # "queued" para reprocesamiento
print(f"ID: {updated.id}")  # "memory_id_123"
```

```bash cURL
curl -X PATCH "https://api.supermemory.ai/v3/documents/memory_id_123" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Updated content here",
    "metadata": {"version": 2, "updated": true}
  }'
```

</CodeGroup>

<div id="upserts-using-customid">
  ## Upserts con customId
</div>

Usa `customId` para operaciones idempotentes: cuando llamas a `add()` con el mismo `customId`, se actualiza la memory existente en lugar de crear duplicados.

<CodeGroup>

```typescript Typescript
import Supermemory from 'supermemory';

const client = new Supermemory({
  apiKey: process.env.SUPERMEMORY_API_KEY!
});

const customId = 'user-note-001';

// Primera llamada: crea la memory
const created = await client.memories.add({
  content: 'Initial content',
  customId: customId,
  metadata: { version: 1 }
});

console.log('Memory creada:', created.id);

// Segunda llamada con el mismo customId: actualiza la existente
const updated = await client.memories.add({
  content: 'Updated content',
  customId: customId,         // Mismo customId = upsert
  metadata: { version: 2 }
});
```

```python Python
from supermemory import Supermemory
import os

client = Supermemory(api_key=os.environ.get("SUPERMEMORY_API_KEY"))

custom_id = 'user-note-001'

# Primera llamada: crea la memory
created = client.memories.add(
    content='Initial content',
    custom_id=custom_id,
    metadata={'version': 1}
)

print(f'Memory creada: {created.id}')

# Segunda llamada con el mismo customId: actualiza la existente
updated = client.memories.add(
    content='Updated content',
    custom_id=custom_id,     # Mismo customId = upsert
    metadata={'version': 2}
)

print(f'Memory actualizada: {updated.id}')
print(f'¿Es la misma memory? {created.id == updated.id}')  # True
```

```bash cURL
# Primera llamada: crea la memory
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Initial content",
    "customId": "user-note-001",
    "metadata": {"version": 1}
  }'

# Response: {"id": "mem_abc123", "status": "queued", "customId": "user-note-001"}

# Segunda llamada: actualiza la existente (mismo customId)
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Updated content",
    "customId": "user-note-001",
    "metadata": {"version": 2}
  }'

# Response: {"id": "mem_abc123", "status": "queued", "customId": "user-note-001"}
# Nota: se devuelve el mismo ID: la memory se actualizó, no se creó.
```

</CodeGroup>

<Note>
El `customId` habilita la idempotencia en todos los endpoints. El `memoryId` no admite idempotencia; solo el `customId` la admite.
</Note>

<div id="single-delete">
  ## Eliminación individual
</div>

Elimina memorias individuales por su id. Esta es una eliminación definitiva sin posibilidad de recuperación.

<CodeGroup>

```typescript Typescript
// Eliminación definitiva: elimina la memory de forma permanente
await client.memories.delete('memory_id_123');
console.log('Memory deleted successfully');
```

```python Python
# Eliminación definitiva: elimina la memory de forma permanente
client.memories.delete('memory_id_123')
print('Memory deleted successfully')

# Manejo de errores para eliminación individual
try:
    client.memories.delete('memory_id_123')
    print('Delete successful')
except NotFoundError:
    print('Memory not found or already deleted')
except AuthenticationError:
    print('Authentication failed')
except Exception as e:
    print(f'Delete failed: {e}')
```

```bash cURL
curl -X DELETE "https://api.supermemory.ai/v3/documents/memory_id_123" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY"

# Respuesta: 204 No Content (éxito)
# Respuesta: 404 Not Found (la memory no existe)
```

</CodeGroup>

<div id="bulk-delete-by-ids">
  ## Eliminación masiva por IDs
</div>

Elimina varias memories a la vez proporcionando un arreglo de IDs de memory. Máximo 100 IDs por solicitud.

<CodeGroup>

```typescript Typescript
// Eliminación masiva por IDs de memory
const result = await client.memories.bulkDelete({
  ids: [
    'memory_id_1',
    'memory_id_2',
    'memory_id_3',
    'non_existent_id'  // Esto se reportará en errors
  ]
});

console.log('Resultado de la eliminación masiva:', result);
// Output: {
//   success: true,
//   deletedCount: 3,
//   errors: [
//     { id: "non_existent_id", error: "Memory not found" }
//   ]
// }
```

```python Python
# Eliminación masiva por IDs de memory
result = client.memories.bulk_delete(
    ids=[
        'memory_id_1',
        'memory_id_2',
        'memory_id_3',
        'non_existent_id'  # Esto se reportará en errors
    ]
)

print(f'Resultado de la eliminación masiva: {result}')
# Output: {
#   'success': True,
#   'deletedCount': 3,
#   'errors': [
#     {'id': 'non_existent_id', 'error': 'Memory not found'}
#   ]
# }
```

```bash cURL
curl -X DELETE "https://api.supermemory.ai/v3/documents/bulk" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "ids": [
      "memory_id_1",
      "memory_id_2",
      "memory_id_3",
      "non_existent_id"
    ]
  }'

# Response: {
#   "success": true,
#   "deletedCount": 3,
#   "errors": [
#     {"id": "non_existent_id", "error": "Memory not found"}
#   ]
# }
```

</CodeGroup>

<div id="bulk-delete-by-container-tags">
  ## Eliminación masiva por etiquetas de contenedor
</div>

Elimina todas las memories dentro de etiquetas de contenedor específicas. Es útil para limpiar proyectos completos o datos de usuarios.

<CodeGroup>

```typescript Typescript
// Delete all memories in specific container tags
const result = await client.memories.bulkDelete({
  containerTags: ['user-123', 'project-old', 'archived-content']
});

console.log('Bulk delete by tags result:', result);
// Output: {
//   success: true,
//   deletedCount: 45,
//   containerTags: ["user-123", "project-old", "archived-content"]
// }
```

```python Python
# Delete all memories in specific container tags
result = client.memories.bulk_delete(
    container_tags=['user-123', 'project-old', 'archived-content']
)

print(f'Bulk delete by tags result: {result}')
# Output: {
#   'success': True,
#   'deletedCount': 45,
#   'containerTags': ['user-123', 'project-old', 'archived-content']
# }
```

```bash cURL
curl -X DELETE "https://api.supermemory.ai/v3/documents/bulk" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "containerTags": ["user-123", "project-old", "archived-content"]
  }'

# Response: {
#   "success": true,
#   "deletedCount": 45,
#   "containerTags": ["user-123", "project-old", "archived-content"]
# }
```

</CodeGroup>

<div id="advanced-patterns">
  ## Patrones avanzados
</div>

<div id="soft-delete-implementation">
  ### Implementación de borrado lógico
</div>

Para aplicaciones que requieren trazabilidad o mecanismos de recuperación, implementa patrones de borrado lógico usando metadata:

<CodeGroup>

```typescript Typescript
// Patrón de borrado lógico usando metadata
await client.memories.update('memory_id', {
  metadata: {
    deleted: true,
    deletedAt: new Date().toISOString(),
    deletedBy: 'user_123'
  }
});

// Excluir memories borradas en las búsquedas
const activeMemories = await client.memories.list({
  filters: JSON.stringify({
    AND: [
      { key: "deleted", value: "true", negate: true }
    ]
  })
});

console.log('Memories activas:', activeMemories.results.length);
```

```python Python
from datetime import datetime
import json

# Patrón de borrado lógico usando metadata
client.memories.update('memory_id', {
    'metadata': {
        'deleted': True,
        'deletedAt': datetime.now().isoformat(),
        'deletedBy': 'user_123'
    }
})

# Excluir memories borradas
active_memories = client.memories.list(
    filters=json.dumps({
        "AND": [
            {"key": "deleted", "value": "true", "negate": True}
        ]
    })
)

print(f'Memories activas: {len(active_memories.results)}')
```

```bash cURL
# Borrado lógico usando metadata
curl -X PATCH "https://api.supermemory.ai/v3/documents/memory_id" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "metadata": {
      "deleted": true,
      "deletedAt": "2024-01-15T10:30:00Z",
      "deletedBy": "user_123"
    }
  }'

# Respuesta: {"id": "memory_id", "status": "queued"}
```

</CodeGroup>

<div id="batch-processing-for-large-operations">
  ### Procesamiento por lotes para operaciones de gran tamaño
</div>

<CodeGroup>

```typescript Typescript
// Eliminar de forma segura grandes cantidades de memories por lotes
async function batchDeleteMemories(memoryIds: string[], batchSize = 100) {
  const results = [];

  for (let i = 0; i < memoryIds.length; i += batchSize) {
    const batch = memoryIds.slice(i, i + batchSize);

    console.log(`Procesando lote ${Math.floor(i/batchSize) + 1} de ${Math.ceil(memoryIds.length/batchSize)}`);

    try {
      const result = await client.memories.bulkDelete({ ids: batch });
      results.push(result);

      // Breve pausa entre lotes para evitar la limitación de tasa
      if (i + batchSize < memoryIds.length) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    } catch (error) {
      console.error(`El lote ${Math.floor(i/batchSize) + 1} falló:`, error);
      results.push({ success: false, error: error.message, batch });
    }
  }

  // Agregar resultados
  const totalDeleted = results
    .filter(r => r.success)
    .reduce((sum, r) => sum + (r.deletedCount || 0), 0);

  console.log(`Total eliminados: ${totalDeleted} de ${memoryIds.length}`);
  return { totalDeleted, results };
}
```

```python Python
import time
import math

def batch_delete_memories(memory_ids, batch_size=100):
    """Eliminar de forma segura grandes cantidades de memories por lotes"""
    results = []

    for i in range(0, len(memory_ids), batch_size):
        batch = memory_ids[i:i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = math.ceil(len(memory_ids) / batch_size)

        print(f'Procesando lote {batch_num} de {total_batches}')

        try:
            result = client.memories.bulk_delete(ids=batch)
            results.append(result)

            # Breve pausa entre lotes para evitar la limitación de tasa
            if i + batch_size < len(memory_ids):
                time.sleep(1)
        except Exception as error:
            print(f'El lote {batch_num} falló: {error}')
            results.append({'success': False, 'error': str(error), 'batch': batch})

    # Agregar resultados
    total_deleted = sum(
        r.get('deletedCount', 0) for r in results if r.get('success')
    )

    print(f'Total eliminados: {total_deleted} de {len(memory_ids)}')
    return {'totalDeleted': total_deleted, 'results': results}
```

```bash cURL
# Ejemplo de script de procesamiento por lotes
#!/bin/bash

MEMORY_IDS=("id1" "id2" "id3")  # Tu arreglo de IDs de memory
BATCH_SIZE=100
TOTAL_DELETED=0

# Procesar por lotes
for ((i=0; i<${#MEMORY_IDS[@]}; i+=BATCH_SIZE)); do
    batch=("${MEMORY_IDS[@]:i:BATCH_SIZE}")
    batch_json=$(printf '%s\n' "${batch[@]}" | jq -R . | jq -s .)

    echo "Procesando lote $((i/BATCH_SIZE + 1))"

    response=$(curl -s -X DELETE \
      "https://api.supermemory.ai/v3/documents/bulk" \
      -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
      -H "Content-Type: application/json" \
      -d "{\"ids\": $batch_json}")

    deleted_count=$(echo "$response" | jq -r '.deletedCount // 0')
    TOTAL_DELETED=$((TOTAL_DELETED + deleted_count))

    echo "Lote eliminado: $deleted_count memories"
    sleep 1  # Protección contra la limitación de tasa
done

echo "Total eliminados: $TOTAL_DELETED memories"
```

</CodeGroup>

<div id="best-practices">
  ## Prácticas recomendadas
</div>

<div id="update-operations">
  ### Operaciones de actualización
</div>

1. **Usa customId para actualizaciones idempotentes** - Evita memories duplicadas y permite reintentos seguros
2. **Supervisa el status de procesamiento** - Las actualizaciones disparan el pipeline completo de reprocesamiento
3. **Gestiona la metadata con cuidado** - Las actualizaciones sustituyen las claves de metadata especificadas
4. **Implementa un manejo de errores adecuado** - La memory puede eliminarse entre operaciones

<div id="delete-operations">
  ### Operaciones de eliminación
</div>

1. **La eliminación total es permanente** - No hay mecanismo de recuperación
2. **Usa operaciones masivas de forma eficiente** - Máximo 100 IDs por solicitud de eliminación masiva
3. **Considera patrones de eliminación lógica (soft delete)** - Usa flags en la metadata para eliminaciones recuperables
4. **Agrupa operaciones grandes** - Evita los límites de velocidad con un agrupamiento adecuado
5. **Limpia el estado de la aplicación** - Actualiza la UI/caché después de las eliminaciones