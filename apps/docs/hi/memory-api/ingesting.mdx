---
title: "दस्तावेज़ और डेटा इनजेस्ट करें"
sidebarTitle: "कंटेंट इनजेस्ट करने की गाइड"
description: "Supermemory में टेक्स्ट, URL, फाइलें और विभिन्न कंटेंट प्रकार इनजेस्ट करने की संपूर्ण गाइड"
---

Supermemory एक शक्तिशाली और लचीला इनजेशन सिस्टम प्रदान करता है जो लगभग हर प्रकार के कंटेंट को प्रोसेस कर सकता है। चाहे आप साधारण टेक्स्ट नोट्स, वेब पेज, PDF, इमेज, या विभिन्न प्लेटफ़ॉर्म से आने वाले जटिल documents जोड़ रहे हों, हमारा API इसे निर्बाध रूप से संभालता है।

<div id="understanding-the-mental-model">
  ## मानसिक मॉडल को समझना
</div>

API में जाने से पहले, यह समझना महत्वपूर्ण है कि Supermemory आपकी सामग्री को कैसे संसाधित करता है:

<div id="documents-vs-memories">
  ### Documents बनाम मेमोरी
</div>

* **Documents**: जो कुछ भी आप Supermemory में डालते हैं (files, URLs, text) उसे **document** माना जाता है
* **मेमोरी**: Documents अपने आप छोटे, खोजयोग्य हिस्सों में विभाजित हो जाते हैं जिन्हें **मेमोरी** कहा जाता है

जब आप &quot;Add Memory&quot; endpoint का उपयोग करते हैं, तो वास्तव में आप एक **document** जोड़ रहे होते हैं। Supermemory का काम उस document को बुद्धिमानी से इष्टतम **मेमोरी** में तोड़ना है जिन्हें खोजा और प्राप्त किया जा सके।

```
आपकी सामग्री → दस्तावेज़ → प्रसंस्करण → कई संग्रहीत स्मृतियाँ
     ↓             ↓           ↓            ↓
   PDF फ़ाइल → संग्रहीत दस्तावेज़ → चंकिंग → खोजने योग्य संग्रहीत स्मृतियाँ
```

आप इस प्रक्रिया को [Supermemory Console](https://console.supermemory.ai) में देख सकते हैं, जहाँ आपको एक ग्राफ़ व्यू दिखाई देगा जो दिखाता है कि आपके documents किस तरह आपस में जुड़ी हुई मेमोरी में विभाजित होते हैं।

<div id="content-sources">
  ### सामग्री स्रोत
</div>

Supermemory तीन मुख्य तरीकों से सामग्री लेता है:

1. **Direct API**: फ़ाइलें अपलोड करें या API endpoints के जरिए सामग्री भेजें
2. **Connectors**: Google Drive, Notion और OneDrive जैसे प्लेटफ़ॉर्म के साथ स्वचालित इंटीग्रेशन ([connectors के बारे में और जानें](/hi/connectors))
3. **URL Processing**: वेब पेज, वीडियो और सोशल मीडिया से स्वचालित एक्स्ट्रैक्शन

<div id="overview">
  ## अवलोकन
</div>

इंजेशन सिस्टम कई प्रमुख घटकों से मिलकर बना है:

* **एकाधिक इनपुट तरीक़े**: JSON सामग्री, फ़ाइल अपलोड, और url प्रोसेसिंग
* **असिंक्रोनस प्रोसेसिंग**: बैकग्राउंड वर्कफ़्लो सामग्री निष्कर्षण और चंकिंग को संभालते हैं
* **ऑटो कंटेंट डिटेक्शन**: अलग-अलग कंटेंट प्रकारों की स्वचालित पहचान और प्रोसेसिंग करता है
* **स्पेस संगठन**: कंटेनर टैग बेहतर संदर्भ निष्कर्षण के लिए संबंधित संग्रहीत स्मृतियाँ समूहित करते हैं
* **स्टेटस ट्रैकिंग**: प्रोसेसिंग पाइपलाइन के दौरान रीयल-टाइम स्टेटस अपडेट

<div id="how-it-works">
  ### यह कैसे काम करता है
</div>

<Steps>
  <Step title="दस्तावेज़ सबमिट करें">
    नया दस्तावेज़ बनाने के लिए अपना कंटेंट (टेक्स्ट, फ़ाइल या url) भेजें
  </Step>

  <Step title="मान्यकरण">
    API अनुरोध को मान्य करता है और रेट लिमिट/कोटा की जाँच करता है
  </Step>

  <Step title="दस्तावेज़ संग्रहण">
    आपका कंटेंट एक दस्तावेज़ के रूप में संग्रहीत होता है और प्रोसेसिंग के लिए प्रतीक्षा में रखा जाता है
  </Step>

  <Step title="कंटेंट एक्सट्रैक्शन">
    विशेषीकृत एक्सट्रैक्टर दस्तावेज़ को उसके प्रकार के आधार पर प्रोसेस करते हैं
  </Step>

  <Step title="मेमोरी क्रिएशन">
    दस्तावेज़ को बुद्धिमानी से कई खोजयोग्य संग्रहीत स्मृतियों में विभाजित किया जाता है
  </Step>

  <Step title="एंबेडिंग और इंडेक्सिंग">
    संग्रहीत स्मृतियों को वेक्टर एंबेडिंग में बदला जाता है और खोजयोग्य बनाया जाता है
  </Step>
</Steps>

<div id="ingestion-endpoints">
  ## इनजेस्टion एंडपॉइंट्स
</div>

<div id="add-document-json-content">
  ### दस्तावेज़ जोड़ें - JSON सामग्री
</div>

ऐसी सामग्री जोड़ने के लिए प्राथमिक endpoint जिसे प्रोसेस करके documents बनाया जाएगा।

**Endpoint:** `POST /v3/documents`

<Note>
  Endpoint नाम के बावजूद, आप एक **document** बना रहे हैं जिसे Supermemory स्वचालित रूप से खोजयोग्य **संग्रहीत स्मृतियाँ** में विभाजित कर देता है।
</Note>

<CodeGroup>
  ```bash cURL
  curl https://api.supermemory.ai/v3/documents \
    -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "content": "Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without explicit programming.",
      "containerTags": ["ai-research", "user_123"],
      "metadata": {
        "source": "research-notes",
        "category": "education",
        "priority": "high"
      },
      "customId": "ml-basics-001"
    }'
  ```

  ```typescript TypeScript
  import Supermemory from 'supermemory'

  const client = new Supermemory({
    apiKey: process.env.SUPERMEMORY_API_KEY
  })

  async function addContent() {
      const result = await client.memories.add({
          content: "Machine learning is a subset of artificial intelligence...",
          containerTags: ["ai-research"],
          metadata: {
            source: "research-notes",
            category: "education",
            priority: "high"
          },
          customId: "ml-basics-001"
        })

        console.log(result) // { id: "abc123", status: "queued" }
  }

   addContent()
  ```

  ```python Python
  from supermemory import Supermemory
  import os

  client = Supermemory(api_key=os.environ.get("SUPERMEMORY_API_KEY"))

  result = client.memories.add(
      content="Machine learning is a subset of artificial intelligence...",
      container_tags=["ai-research"],
      metadata={
          "source": "research-notes",
          "category": "education",
          "priority": "high"
      },
      custom_id="ml-basics-001"
  )

  print(result)  # { "id": "abc123", "status": "queued" }
  ```
</CodeGroup>

<div id="request-parameters">
  #### अनुरोध पैरामीटर
</div>

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `content` | string | Yes | वह सामग्री जिसे दस्तावेज़ में प्रोसेस करना है। टेक्स्ट, URL, या अन्य समर्थित फ़ॉर्मैट हो सकती है |
| `containerTag` | string | No | **अनुशंसित**: संबंधित संग्रहीत स्मृतियों को एक स्पेस में समूहित करने के लिए एकल टैग। डिफ़ॉल्ट `"sm_project_default"` |
| `containerTags` | string[] | No | पुराना array फ़ॉर्मैट। बेहतर प्रदर्शन के लिए `containerTag` का उपयोग करें |
| `metadata` | object | No | अतिरिक्त कुंजी-मूल्य Metadata (केवल strings, numbers, booleans) |
| `customId` | string | No | इस दस्तावेज़ के लिए आपका अपना पहचानकर्ता (अधिकतम 255 वर्ण) |
| `raw` | string | No | प्रोसेस्ड सामग्री के साथ-साथ संग्रहीत करने हेतु रॉ सामग्री |

<div id="response">
  #### प्रतिक्रिया
</div>

जब आप कोई दस्तावेज़ सफलतापूर्वक बनाते हैं, तो आपको दस्तावेज़ id और उसके प्रारंभिक प्रोसेसिंग स्टेटस के साथ एक सरल पुष्टि संदेश मिलता है:

```json
{
  "id": "D2Ar7Vo7ub83w3PRPZcaP1",
  "status": "प्रतीक्षा में"
}
```

**इसका मतलब:**

* `id`: आपके दस्तावेज़ का अद्वितीय पहचानकर्ता — प्रोसेसिंग ट्रैक करने या बाद में संदर्भ के लिए इसे सहेजें
* `status`: वर्तमान प्रोसेसिंग स्थिति। `"queued"` का मतलब है कि यह संग्रहीत स्मृतियों में प्रोसेस होने के लिए प्रतीक्षा में है

<Note>
  दस्तावेज़ का प्रोसेसिंग बैकग्राउंड में तुरंत शुरू हो जाता है। कुछ सेकंड से कुछ मिनटों के भीतर (कंटेंट के आकार पर निर्भर), इसे खोजने योग्य संग्रहीत स्मृतियों में विभाजित कर दिया जाएगा।
</Note>

<div id="file-upload-drop-and-process">
  ### फ़ाइल अपलोड: ड्रॉप करें और प्रोसेस करें
</div>

PDF, इमेज या वीडियो है? इसे सीधे अपलोड करें और Supermemory को मूल्यवान सामग्री स्वतः निकालने दें।

**एंडपॉइंट:** `POST /v3/documents/file`

**यह क्यों शक्तिशाली है:** PDFs से टेक्स्ट मैन्युअल रूप से कॉपी करने या वीडियो को ट्रांसक्राइब करने के बजाय, बस फ़ाइल अपलोड करें। Supermemory इमेज के लिए OCR, वीडियो के लिए ट्रांसक्रिप्शन, और documents के लिए बुद्धिमान टेक्स्ट एक्सट्रैक्शन संभालता है।

<CodeGroup>
  ```bash cURL
  curl https://api.supermemory.ai/v3/documents/file \
    -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
    -F "file=@document.pdf" \
    -F "containerTags=research_project"

  # Response:
  # {
  #   "id": "Mx7fK9pL2qR5tE8yU4nC7",
  #   "status": "processing"
  # }
  ```

  ```typescript TypeScript
  import Supermemory from 'supermemory'
  import fs from 'fs'

  const client = new Supermemory({
    apiKey: process.env.SUPERMEMORY_API_KEY
  })

  // Method 1: Using SDK uploadFile method (RECOMMENDED)
  const result = await client.memories.uploadFile({
    file: fs.createReadStream('/path/to/document.pdf'),
    containerTags: 'research_project'  // String, not array!
  })

  // Method 2: Using fetch with form data (for browser/manual implementation)
  const formData = new FormData()
  formData.append('file', fileInput.files[0])
  formData.append('containerTags', 'research_project')

  const response = await fetch('https://api.supermemory.ai/v3/documents/file', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.SUPERMEMORY_API_KEY}`
    },
    body: formData
  })

  const result = await response.json()
  console.log(result)
  // Output: { id: "Mx7fK9pL2qR5tE8yU4nC7", status: "processing" }
  ```

  ```python Python
  from supermemory import Supermemory

  client = Supermemory(api_key="your_api_key")

  # Method 1: Using SDK upload_file method (RECOMMENDED)
  result = client.memories.upload_file(
      file=open('document.pdf', 'rb'),
      container_tags='research_project'  # String parameter name
  )

  # Method 2: Using requests with form data
  import requests

  files = {'file': open('document.pdf', 'rb')}
  data = {'containerTags': 'research_project'}

  response = requests.post(
      'https://api.supermemory.ai/v3/documents/file',
      headers={'Authorization': f'Bearer {api_key}'},
      files=files,
      data=data
  )

  result = response.json()
  print(result)
  # Output: {'id': 'Mx7fK9pL2qR5tE8yU4nC7', 'status': 'processing'}
  ```
</CodeGroup>

<div id="supported-file-types">
  #### समर्थित फ़ाइल प्रकार
</div>

<Tabs>
  <Tab title="Documents">
    * **PDF**: स्कैन किए गए documents के लिए OCR (Optical Character Recognition) समर्थन के साथ निष्कर्षण
    * **Google Docs**: Google Drive API इंटीग्रेशन के माध्यम से
    * **Google Sheets**: स्प्रेडशीट सामग्री निष्कर्षण
    * **Google Slides**: प्रेज़ेंटेशन सामग्री निष्कर्षण
    * **Notion Pages**: ब्लॉक संरचना सुरक्षित रखते हुए समृद्ध सामग्री
    * **OneDrive Documents**: Microsoft Office documents
  </Tab>

  <Tab title="Media">
    * **Images**: JPG, PNG, GIF, WebP से OCR के माध्यम से टेक्स्ट निष्कर्षण
    * **Videos**: MP4, WebM, AVI के लिए ट्रांसक्रिप्शन (YouTube, Vimeo)
  </Tab>

  <Tab title="Web Content">
    * **Web Pages**: किसी भी सार्वजनिक url से बुद्धिमान सामग्री निष्कर्षण
    * **Twitter/X Posts**: ट्वीट सामग्री और Metadata
    * **YouTube Videos**: स्वचालित ट्रांसक्रिप्शन और Metadata
  </Tab>

  <Tab title="Text Formats">
    * **Plain Text**: TXT, MD, CSV फ़ाइलें
  </Tab>
</Tabs>

<div id="content-types-processing">
  ## सामग्री प्रकार और प्रसंस्करण
</div>

<div id="automatic-detection">
  ### स्वचालित पहचान
</div>

Supermemory निम्न आधारों पर सामग्री प्रकारों का स्वचालित रूप से पता लगाता है:

* **url पैटर्न**: विशेष सेवाओं के लिए डोमेन और पाथ का विश्लेषण
* **MIME प्रकार**: हेडर/Metadata से फ़ाइल प्रकार का निर्धारण
* **सामग्री विश्लेषण**: संरचना और फ़ॉर्मेट का परीक्षण
* **फ़ाइल एक्सटेंशन**: बैकअप/फॉलबैक पहचान विधि

```typescript

type MemoryType =
  | 'text'        // सादा टेक्स्ट कंटेंट
  | 'pdf'         // PDF documents
  | 'tweet'       // Twitter/X पोस्ट
  | 'google_doc'  // Google Docs
  | 'google_slide'// Google Slides
  | 'google_sheet'// Google Sheets
  | 'image'       // OCR के साथ इमेज
  | 'video'       // ट्रांसक्रिप्शन के साथ वीडियो
  | 'notion_doc'  // Notion पेज
  | 'webpage'     // वेब पेज
  | 'onedrive'    // OneDrive documents



// स्वचालित पहचान के उदाहरण
const examples = {
  "https://twitter.com/user/status/123": "tweet",
  "https://youtube.com/watch?v=abc": "video",
  "https://docs.google.com/document/d/123": "google_doc",
  "https://docs.google.com/spreadsheets/d/123": "google_sheet",
  "https://docs.google.com/presentation/d/123": "google_slide",
  "https://notion.so/page-123": "notion_doc",
  "https://example.com": "webpage",
  "Regular text content": "text",
  // PDF फाइलें अपलोड की गईं → "pdf"
  // इमेज फाइलें अपलोड की गईं → "image"
  // OneDrive लिंक → "onedrive"
}
```

<div id="processing-pipeline">
  ### प्रोसेसिंग पाइपलाइन
</div>

प्रत्येक कंटेंट प्रकार एक विशेषीकृत प्रोसेसिंग पाइपलाइन का पालन करता है:

<Accordion title="Text Content" defaultOpen>
  बेहतर रिट्रीवल के लिए कंटेंट को साफ़ किया जाता है, सामान्यीकृत किया जाता है, और चंक किया जाता है:

  1. **प्रतीक्षा में**: मेमोरी प्रोसेसिंग कतार में जाती है
  2. **एक्सट्रैक्टिंग**: टेक्स्ट नॉर्मलाइज़ेशन और क्लीनिंग
  3. **चंकिंग**: कंटेंट संरचना के आधार पर बुद्धिमानी से विभाजन
  4. **एंबेडिंग**: सर्च के लिए वेक्टर रिप्रेज़ेंटेशन में रूपांतरण
  5. **इंडेक्सिंग**: सर्चेबल इंडेक्स में जोड़ना
  6. **पूर्ण:** Metadata एक्सट्रैक्शन पूरा
</Accordion>

<Accordion title="Web Content">
  वेब पेजों पर उन्नत कंटेंट एक्सट्रैक्शन लागू होता है:

  1. **प्रतीक्षा में:** url प्रोसेसिंग के लिए प्रतीक्षा में
  2. **एक्सट्रैक्टिंग**: उपयुक्त हेडर के साथ पेज कंटेंट फ़ेच करना, नेविगेशन और बोइलरप्लेट हटाना, title, विवरण आदि निकालना
  3. **चंकिंग:** बेहतर रिट्रीवल के लिए कंटेंट का विभाजन
  4. **एंबेडिंग**: वेक्टर रिप्रेज़ेंटेशन जनरेशन
  5. **इंडेक्सिंग**: सर्च इंडेक्स में जोड़ना
  6. **पूर्ण:** `type: 'webpage'` के साथ प्रोसेसिंग पूर्ण
</Accordion>

<Accordion title="File Processing">
  फाइलें विशेषीकृत एक्सट्रैक्टर्स के माध्यम से प्रोसेस की जाती हैं:

  1. **प्रतीक्षा में**: फाइल प्रोसेसिंग के लिए प्रतीक्षा में
  2. **कंटेंट एक्सट्रैक्शन**: टाइप डिटेक्शन और फॉर्मेट-विशिष्ट प्रोसेसिंग
  3. **OCR/Transcription**: इमेज और मीडिया फाइलों के लिए
  4. **चंकिंग:** कंटेंट को सर्चेबल सेगमेंट्स में विभाजित करना
  5. **एंबेडिंग:** वेक्टर रिप्रेज़ेंटेशन निर्माण
  6. **इंडेक्सिंग:** सर्च इंडेक्स में जोड़ना
  7. **पूर्ण:** प्रोसेसिंग पूर्ण
</Accordion>

<div id="error-handling">
  ## त्रुटि हैंडलिंग
</div>

<div id="common-errors">
  ### सामान्य त्रुटियाँ
</div>

और देखने के लिए दाईं ओर स्क्रॉल करें।

<Tabs>
  <Tab title="Authentication Errors">
    ```json
    // AuthenticationError class
    {
      name: "AuthenticationError",
      status: 401,
      message: "401 Unauthorized",
      error: {
        message: "Invalid API key",
        type: "authentication_error"
      }
    }
    ```

    **कारण:**

    * API कुंजी गायब है या अमान्य है
    * प्रमाणीकरण टोकन की समय-सीमा समाप्त हो गई
    * authorization हेडर का फ़ॉर्मेट गलत है
  </Tab>

  <Tab title="Bad Request Errors (400)">
    ```json
    // BadRequestError class
    {
      name: "BadRequestError",
      status: 400,
      message: "400 Bad Request",
      error: {
        message: "Invalid request parameters",
        details: {
          content: "Content cannot be empty",
          customId: "customId exceeds maximum length"
        }
      }
    }
    ```

    **कारण:**

    * आवश्यक फ़ील्ड गायब
    * पैरामीटर प्रकार अमान्य
    * कंटेंट बहुत बड़ा है
    * Custom ID बहुत लंबा है
    * Metadata संरचना अमान्य
  </Tab>

  <Tab title="Rate Limiting (429)">
    ```json
    // RateLimitError class
    {
      name: "RateLimitError",
      status: 429,  // NOT 402!
      message: "429 Too Many Requests",
      error: {
        message: "Rate limit exceeded",
        retry_after: 60
      }
    }
    ```

    **कारण:**

    * मासिक टोकन कोटा पार हो गया
    * रेट लिमिट पार हो गई
    * सदस्यता सीमाएँ पूरी हो गईं

    **समाधान:** एक्सपोनेंशियल बैकऑफ़ लागू करें और रेट लिमिट का पालन करें
  </Tab>

  <Tab title="Not Found Errors (404)">
    ```json
    // NotFoundError class
    {
      name: "NotFoundError",
      status: 404,
      message: "404 Not Found",
      error: {
        message: "Memory not found",
        resource_id: "invalid_memory_id"
      }
    }
    ```

    कारण:

    * Memory ID मौजूद नहीं है
    * Memory हटाई जा चुकी है
    * endpoint URL अमान्य है
  </Tab>

  <Tab title="Permission Denied (403)">
    ```json
    // PermissionDeniedError class
    {
      name: "PermissionDeniedError",
      status: 403,
      message: "403 Forbidden",
      error: {
        message: "Insufficient permissions",
        required_permission: "memories:write"
      }
    }
    ```

    कारण:

    * API कुंजी में आवश्यक permissions नहीं हैं
    * प्रतिबंधित संसाधनों का एक्सेस
    * खाते की सीमाएँ
  </Tab>

  <Tab title="Server Errors (500+)">
    ```json
    // InternalServerError class
    {
      name: "InternalServerError",
      status: 500,
      message: "500 Internal Server Error",
      error: {
        message: "Processing failed",
        details: "Content extraction service unavailable"
      }
    }
    ```

    **कारण:**

    * बाहरी सेवा उपलब्ध नहीं है
    * कंटेंट एक्सट्रैक्शन विफल
  </Tab>

  <Tab title="Network Errors">
    ```json
        // APIConnectionError class - NEW
      {
        name: "APIConnectionError",
        message: "Connection error.",
        cause: Error // Original network error
      }

      // APIConnectionTimeoutError class - NEW
      {
        name: "APIConnectionTimeoutError",
        message: "Request timed out."
      }
    ```

    कारण:

    * नेटवर्क कनेक्टिविटी समस्याएँ
    * DNS रेज़ोल्यूशन विफलताएँ
    * रिक्वेस्ट टाइमआउट
    * प्रॉक्सी/फ़ायरवॉल द्वारा ब्लॉक करना
  </Tab>
</Tabs>

<div id="best-practices">
  ## सर्वोत्तम अभ्यास
</div>

<div id="container-tags-optimize-for-performance">
  ### Container Tags: प्रदर्शन के लिए अनुकूलित करें
</div>

बेहतर क्वेरी प्रदर्शन के लिए एकल container टैग का उपयोग करें। एक से अधिक टैग समर्थित हैं, लेकिन वे विलंबता बढ़ाते हैं।

```json
{
  "content": "JWT टोकन का उपयोग करने के लिए प्रमाणीकरण प्रवाह को अपडेट किया गया",
  "containerTags": "[project_alpha]",
  "metadata": {
    "type": "technical_change",
    "author": "sarah_dev",
    "impact": "breaking"
  }
}
```

**एकल बनाम बहु-टैग**

```javascript
// ✅ अनुशंसित: एकल टैग, तेज़ क्वेरीज़
{ "containerTags": ["project_alpha"] }

// ⚠️ अनुमतित लेकिन धीमा: कई टैग विलंबता बढ़ाते हैं
{ "containerTags": ["project_alpha", "auth", "backend"] }
```

**एकल टैग बेहतर प्रदर्शन क्यों करते हैं:**

* एक ही स्पेस में संग्रहीत स्मृतियाँ एक‑दूसरे को कुशलतापूर्वक संदर्भित कर सकती हैं
* सर्च क्वेरीज़ को कई स्पेस में नहीं जाना पड़ता
* एकल स्पेस के भीतर इंटीग्रेशन अनुमान तेज़ होता है

<div id="custom-ids-deduplication-and-updates">
  ### Custom IDs: डिडुप्लिकेशन और अपडेट
</div>

Custom IDs डुप्लिकेट से बचाते हैं और दस्तावेज़ों को अपडेट करने में सक्षम बनाते हैं। दो अपडेट विधियाँ उपलब्ध हैं।

**विधि 1: customId के साथ POST (Upsert)**

```bash
# Document बनाएं
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "API REST endpoints का उपयोग करता है",
    "customId": "api_docs_v1",
    "containerTags": ["project_alpha"]
  }'
# Response: {"id": "abc123", "status": "queued"}

# समान document को अपडेट करें (समान customId = upsert)
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "API GraphQL में माइग्रेट हो गया",
    "customId": "api_docs_v1",
    "containerTags": ["project_alpha"]
  }'
```

**विधि 2: id के माध्यम से PATCH (अपडेट)**

```bash
curl -X PATCH "https://api.supermemory.ai/v3/documents/abc123" \
  -H "Authorization: Bearer $SUPERMEMORY_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "content": "API अब caching के साथ GraphQL का उपयोग करता है",
    "metadata": {"version": 3}
  }'
```

**कस्टम id पैटर्न**

```javascript
// बाहरी सिस्टम सिंक
"jira_PROJ_123"
"confluence_456789"
"github_issue_987"

// डेटाबेस एंटिटीज़
"user_profile_12345"
"order_67890"

// वर्जन्ड कंटेंट
"meeting_2024_01_15"
"api_docs_auth"
"requirements_v3"
```

**अपडेट व्यवहार**

* पुरानी संग्रहीत स्मृतियाँ हटाई जाती हैं
* अद्यतन सामग्री से नई संग्रहीत स्मृतियाँ बनाई जाती हैं
* वही दस्तावेज़ id बनी रहती है

<div id="rate-limits-quotas">
  ### रेट लिमिट्स और कोटा
</div>

**टोकन उपयोग**

```javascript
"Hello world" // ≈ 2 टोकन
"10-page PDF" // ≈ 2,000-4,000 टोकन
"YouTube video (10 min)" // ≈ 1,500-3,000 टोकन
"Web article" // ≈ 500-2,000 टोकन
```

**वर्तमान सीमाएं**

| फ़ीचर | फ्री | स्टार्टर | ग्रोथ |
|---------|------|-----|------------|
| मेमोरी टोकन/माह | 100,000 | 1,000,000 | 10,000,000 |
| खोज क्वेरी/माह | 1,000 | 10,000 | 100,000 |

**सीमा पार होने पर प्रतिक्रिया**

```bash
curl -X POST "https://api.supermemory.ai/v3/documents" \
  -H "Authorization: Bearer your_api_key" \
  -d '{"content": "कुछ कंटेंट"}'
```

उत्तर:

```json
{"error": "मेमोरी टोकन सीमा पहुंच गई", "स्टेटस": 402}
```

<div id="batch-upload-of-documents">
  ## documents का बैच अपलोड
</div>

रेट लिमिटिंग और एरर रिकवरी के साथ बड़े पैमाने को कुशलतापूर्वक प्रोसेस करें।

<div id="implementation-strategy">
  ### इम्प्लीमेंटेशन रणनीति
</div>

<Tabs>
  <Tab title="TypeScript">
    ```typescript
    import Supermemory, {
      BadRequestError,
      RateLimitError,
      AuthenticationError
    } from 'supermemory';

    interface Document {
      id: string;
      content: string;
      title?: string;
      createdAt?: string;
      metadata?: Record<string, string | number | boolean>;
    }

    async function batchIngest(documents: Document[], options = {}) {
      const {
        batchSize = 5,
        delayBetweenBatches = 2000,
        maxRetries = 3
      } = options;

      const results = [];

      for (let i = 0; i < documents.length; i += batchSize) {
        const batch = documents.slice(i, i + batchSize);
        console.log(`बैच ${Math.floor(i/batchSize) + 1}/${Math.ceil(documents.length/batchSize)} को प्रोसेस कर रहे हैं`);

        const batchResults = await Promise.allSettled(
          batch.map(doc => ingestWithRetry(doc, maxRetries))
        );

        results.push(...batchResults);

        // बैचों के बीच रेट लिमिटिंग
        if (i + batchSize < documents.length) {
          await new Promise(resolve => setTimeout(resolve, delayBetweenBatches));
        }
      }

      return results;
    }

    async function ingestWithRetry(doc: Document, maxRetries: number) {
      for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
          return await client.memories.add({
            content: doc.content,
            customId: doc.id,
            containerTags: ["batch_import_user_123"], // सुधारा गया: Array
            metadata: {
              source: "migration",
              batch_id: generateBatchId(),
              original_created: doc.createdAt || new Date().toISOString(),
              title: doc.title || "",
              ...doc.metadata
            }
          });
        } catch (error) {
          // सुधारा गया: उचित एरर हैंडलिंग
          if (error instanceof AuthenticationError) {
            console.error('प्रमाणीकरण असफल - API कुंजी जांचें');
            throw error; // प्रमाणीकरण एरर को पुनः प्रयास न करें
          }

          if (error instanceof BadRequestError) {
            console.error('अमान्य document प्रारूप:', doc.id);
            throw error; // वैलिडेशन एरर को पुनः प्रयास न करें
          }

          if (error instanceof RateLimitError) {
            console.log(`प्रयास ${attempt} पर रेट लिमिट हुआ, अधिक प्रतीक्षा कर रहे हैं...`);
            const delay = Math.pow(2, attempt) * 2000; // रेट लिमिट के लिए लंबी देरी
            await new Promise(resolve => setTimeout(resolve, delay));
            continue;
          }

          if (attempt === maxRetries) throw error;

          // अन्य एरर के लिए एक्सपोनेंशियल बैकऑफ
          const delay = Math.pow(2, attempt) * 1000;
          console.log(`${doc.id} के लिए पुनः प्रयास ${attempt}/${maxRetries} ${delay}ms में`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }

    function generateBatchId(): string {
      return `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    }
    ```
  </Tab>

  <Tab title="Python">
    ```python
        import asyncio
    import time
    import logging
    from typing import List, Dict, Any, Optional
    from supermemory import Supermemory, BadRequestError, RateLimitError

    async def batch_ingest(
        documents: List[Dict[str, Any]],
        options: Optional[Dict[str, Any]] = None
    ):
        options = options or {}
        batch_size = options.get('batch_size', 5)  # सुधारा गया: सुरक्षित आकार
        delay_between_batches = options.get('delay_between_batches', 2.0)  # सुधारा गया: 2 सेकंड
        max_retries = options.get('max_retries', 3)

        results = []

        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(documents) + batch_size - 1) // batch_size

            print(f"Processing batch {batch_num}/{total_batches}")

            # उचित त्रुटि हैंडलिंग के साथ बैच प्रोसेस करें
            tasks = [ingest_with_retry(doc, max_retries) for doc in batch]
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)

            results.extend(batch_results)

            # बैचों के बीच रेट लिमिटिंग
            if i + batch_size < len(documents):
                await asyncio.sleep(delay_between_batches)

        return results

    async def ingest_with_retry(doc: Dict[str, Any], max_retries: int):
        for attempt in range(1, max_retries + 1):
            try:
                return await client.memories.add(
                    content=doc['content'],
                    custom_id=doc['id'],
                    container_tags=["batch_import_user_123"],  # सुधारा गया: सूची
                    metadata={
                        "source": "migration",
                        "batch_id": generate_batch_id(),
                        "original_created": doc.get('created_at', ''),
                        "title": doc.get('title', ''),
                        **doc.get('metadata', {})
                    }
                )
            except BadRequestError as e:
                logging.error(f"Invalid document {doc['id']}: {e}")
                raise  # वैलिडेशन त्रुटियों को पुनः प्रयास न करें

            except RateLimitError as e:
                logging.warning(f"Rate limited on attempt {attempt}")
                delay = 2 ** attempt * 2  # रेट लिमिट के लिए अधिक देरी
                await asyncio.sleep(delay)
                continue

            except Exception as error:
                if attempt == max_retries:
                    raise error

                # एक्सपोनेंशियल बैकऑफ
                delay = 2 ** attempt
                logging.info(f"Retry {attempt}/{max_retries} for {doc['id']} in {delay}s")
                await asyncio.sleep(delay)

    def generate_batch_id() -> str:
        import random
        import string
        return f"batch_{int(time.time())}_{random.choices(string.ascii_lowercase, k=8)}"
    ```
  </Tab>
</Tabs>

<div id="best-practices-for-batch-operations">
  ### बैच ऑपरेशंस के लिए सर्वोत्तम प्रथाएँ
</div>

<Accordion title="Performance Optimization" defaultOpen>
  * **बैच आकार**: एक बार में 3–5 documents
  * **विलंब**: बैचों के बीच 2–3 सेकंड रखें ताकि rate limiting न हो
  * **Promise.allSettled()**: मिश्रित सफलता/विफलता परिणामों को संभालता है
  * **प्रगति ट्रैकिंग**: लंबी चलने वाली प्रक्रियाओं की निगरानी करें

  **नमूना आउटपुट**

  ```
  Processing batch 1/50 (documents 1-3)
  Successfully processed: 2/3 documents
  Failed: 1/3 documents (BadRequestError: Invalid content)
  Progress: 3/150 (2.0%) - Next batch in 2s
  ```
</Accordion>

<Accordion title="Error Handling">
  * **विशिष्ट त्रुटि प्रकार:** `BadRequestError`, `RateLimitError`, `AuthenticationError` को अलग-अलग संभालें
  * **रीट्राई लॉजिक नहीं**: वैलिडेशन या ऑथ त्रुटियों पर रीट्राई न करें
  * **रेट लिमिट हैंडलिंग**: rate limit त्रुटियों के लिए अधिक लंबा बैकऑफ विलंब
  * **लॉगिंग**: समीक्षा/रीट्राई के लिए विफलताओं को रिकॉर्ड करें
</Accordion>

<Accordion title="Memory Management">
  * **स्ट्रीमिंग**: बड़ी फ़ाइलों को चंक्स में प्रोसेस करें
  * **क्लीनअप**: मेमोरी से प्रोसेस्ड बैचों को साफ करें
  * **प्रगति स्थायित्व**: बाधित माइग्रेशन को फिर से शुरू करें
</Accordion>

<Note>
  इनजेस्टिंग शुरू करने के लिए तैयार हैं? अभी [API कुंजी प्राप्त करें](https://console.supermemory.ai)!
</Note>